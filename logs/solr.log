INFO  - 2019-11-19 14:34:56.621; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 14:34:57.903; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 14:34:58.004; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 14:34:58.005; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 14:34:58.019; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 14:34:58.237; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 1613 ms
INFO  - 2019-11-19 14:34:58.264; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 14:34:58.267; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 14:34:58.271; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 14:34:58.271; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 14:34:58.271; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 14:34:58.314; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 14:34:58.320; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 69
INFO  - 2019-11-19 14:34:58.321; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 14:34:58.322; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 14:34:58.857; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 14:34:59.654; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1340 ms
INFO  - 2019-11-19 14:41:52.282; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 14:41:52.288; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 14:41:53.308; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 14:41:53.438; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 14:41:53.750; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 14:41:54.512; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 14:41:54.575; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 14:41:54.576; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 14:41:54.582; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 14:41:54.763; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 14:41:54.765; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 14:41:54.769; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 14:41:54.769; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 14:41:54.769; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 14:41:54.781; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 71
INFO  - 2019-11-19 14:41:54.783; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 14:41:54.783; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 14:41:56.313; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 14:42:05.937; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 12627 ms
INFO  - 2019-11-19 14:42:06.003; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 14:42:06.822; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 14:42:07.138; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1134 ms
INFO  - 2019-11-19 14:49:33.864; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-19 14:49:48.811; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 14:49:48.812; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-19 14:49:48.913; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 14:50:38.062; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 14:50:38.067; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 14:50:38.068; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 14:50:42.119; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 14:50:42.290; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 14:50:42.601; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 14:50:43.449; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 14:50:43.537; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 14:50:43.538; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 14:50:43.546; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 14:50:43.742; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 14:50:43.745; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 14:50:43.750; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 14:50:43.751; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 14:50:43.751; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 14:50:43.766; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 73
INFO  - 2019-11-19 14:50:43.769; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 14:50:43.769; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 14:50:45.139; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 14:50:46.161; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4038 ms
INFO  - 2019-11-19 14:50:46.237; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 14:50:46.578; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 14:50:46.867; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 629 ms
INFO  - 2019-11-19 14:51:19.463; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 14:51:19.468; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 14:51:19.469; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 14:51:22.628; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 14:51:22.775; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 14:51:23.133; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 14:51:24.029; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 14:51:24.111; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 14:51:24.111; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 14:51:24.118; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 14:51:24.367; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 14:51:24.370; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 14:51:24.375; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 14:51:24.375; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 14:51:24.375; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 14:51:24.406; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 75
INFO  - 2019-11-19 14:51:24.409; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 14:51:24.410; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 14:51:25.789; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 14:51:27.266; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4635 ms
INFO  - 2019-11-19 14:51:27.362; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 14:51:27.743; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 14:51:28.013; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 651 ms
INFO  - 2019-11-19 14:58:59.363; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2019-11-19 14:58:59.385; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@17579e0f, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4d41cee, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3712b94, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2833cc44, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33f88ab, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@27a8c74e]
INFO  - 2019-11-19 14:58:59.868; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 14:59:00.426; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 14:59:01.692; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 14:59:01.792; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 14:59:01.793; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 14:59:01.801; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 14:59:02.338; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 14:59:02.340; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 14:59:02.346; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 14:59:02.347; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 14:59:02.347; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 14:59:03.547; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2019-11-19 14:59:03.550; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [articles-0]
INFO  - 2019-11-19 14:59:03.550; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [articles-0]
INFO  - 2019-11-19 14:59:03.551; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 14:59:03.555; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 76
INFO  - 2019-11-19 14:59:03.556; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 14:59:03.556; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 14:59:03.584; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 76
INFO  - 2019-11-19 14:59:03.595; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2019-11-19 14:59:03.596; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2019-11-19 14:59:06.152; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 14:59:07.795; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-19 14:59:08.376; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 14:59:08.385; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 14:59:08.386; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 14:59:09.559; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2019-11-19 14:59:09.561; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [articles-0]
INFO  - 2019-11-19 14:59:09.561; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [articles-0]
INFO  - 2019-11-19 14:59:09.562; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 14:59:09.564; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 77
INFO  - 2019-11-19 14:59:09.565; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 14:59:09.565; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 14:59:09.702; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-19 15:05:03.597; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2019-11-19 15:05:03.613; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@17579e0f, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4d41cee, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3712b94, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2833cc44, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33f88ab, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@27a8c74e]
INFO  - 2019-11-19 15:05:03.880; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:05:04.202; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:05:05.231; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:05:05.299; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:05:05.300; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:05:05.306; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:05:05.507; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:05:05.509; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:05:05.512; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:05:05.512; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:05:05.512; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:05:06.628; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2019-11-19 15:05:06.630; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [articles-0]
INFO  - 2019-11-19 15:05:06.630; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [articles-0]
INFO  - 2019-11-19 15:05:06.630; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:05:06.637; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 78
INFO  - 2019-11-19 15:05:06.637; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 78
INFO  - 2019-11-19 15:05:06.638; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:05:06.638; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:05:06.638; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2019-11-19 15:05:06.638; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2019-11-19 15:05:07.605; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:05:08.946; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-19 15:05:22.674; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:05:22.682; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:05:22.683; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:05:24.173; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-19 15:05:24.641; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2019-11-19 15:05:24.812; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [articles-0]
INFO  - 2019-11-19 15:05:24.812; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [articles-0]
INFO  - 2019-11-19 15:05:24.812; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:05:24.818; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 79
INFO  - 2019-11-19 15:05:24.819; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:05:24.819; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:05:49.443; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2019-11-19 15:05:49.460; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@17579e0f, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4d41cee, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3712b94, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2833cc44, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33f88ab, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@27a8c74e]
INFO  - 2019-11-19 15:05:49.718; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:05:50.083; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:05:51.195; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:05:51.274; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:05:51.274; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:05:51.282; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:05:51.450; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:05:51.452; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:05:51.457; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:05:51.457; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:05:51.458; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:05:53.461; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:05:54.799; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-19 15:05:54.881; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 80
INFO  - 2019-11-19 15:05:54.884; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:05:54.885; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:06:01.350; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:06:01.358; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:06:01.360; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:06:02.969; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-19 15:07:51.730; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:07:52.055; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:07:52.472; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:07:53.738; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:07:53.978; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:07:53.979; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:07:53.986; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:07:54.239; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:07:54.240; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:07:54.245; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:07:54.245; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:07:54.245; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:07:54.277; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 82
INFO  - 2019-11-19 15:07:54.279; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:07:54.279; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:07:56.003; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:07:57.244; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5511 ms
INFO  - 2019-11-19 15:07:57.354; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 15:07:57.786; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 15:07:58.139; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 785 ms
INFO  - 2019-11-19 15:09:28.217; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:09:28.225; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:09:28.227; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:09:30.857; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:09:31.089; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:09:31.465; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:09:32.723; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:09:32.789; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:09:32.790; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:09:32.795; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:09:32.998; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:09:33.000; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:09:33.003; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:09:33.004; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:09:33.004; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:09:33.080; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 84
INFO  - 2019-11-19 15:09:33.082; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:09:33.082; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:09:34.238; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:09:35.211; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4351 ms
INFO  - 2019-11-19 15:09:35.281; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 15:09:35.595; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 15:09:35.906; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 625 ms
INFO  - 2019-11-19 15:09:50.325; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-19 15:13:36.598; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:13:36.603; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:13:36.605; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:13:37.786; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-19 15:13:39.317; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:13:39.493; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:13:39.815; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:13:40.728; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:13:40.809; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:13:40.809; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:13:40.815; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:13:40.999; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:13:41.001; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:13:41.005; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:13:41.006; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:13:41.006; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:13:41.021; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 86
INFO  - 2019-11-19 15:13:41.023; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:13:41.023; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:13:42.398; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:13:45.038; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5718 ms
INFO  - 2019-11-19 15:13:45.139; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 15:13:45.774; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 15:13:46.032; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 893 ms
INFO  - 2019-11-19 15:14:06.496; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-19 15:15:18.479; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:15:18.486; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:15:18.487; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:15:19.876; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-19 15:15:21.063; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:15:21.207; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:15:21.523; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:15:22.399; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:15:22.461; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:15:22.462; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:15:22.469; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:15:22.605; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:15:22.608; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:15:22.612; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:15:22.612; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:15:22.612; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:15:22.621; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 88
INFO  - 2019-11-19 15:15:22.623; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:15:22.623; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:15:23.968; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:15:25.221; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4156 ms
INFO  - 2019-11-19 15:15:25.311; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 15:15:25.712; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 15:15:25.983; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 671 ms
INFO  - 2019-11-19 15:15:48.904; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:15:48.909; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:15:48.911; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:15:52.131; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:15:52.319; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:15:52.631; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:15:53.541; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:15:53.614; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:15:53.615; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:15:53.620; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:15:53.778; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:15:53.780; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:15:53.784; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:15:53.784; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:15:53.785; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:15:53.796; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 90
INFO  - 2019-11-19 15:15:53.798; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:15:53.798; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:15:55.141; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:15:56.461; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4328 ms
INFO  - 2019-11-19 15:15:56.525; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 15:15:56.861; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 15:15:57.164; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 639 ms
INFO  - 2019-11-19 15:16:01.264; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:16:01.269; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:16:01.270; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:16:06.053; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:16:06.229; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:16:06.750; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:16:07.592; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:16:07.667; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:16:07.667; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:16:07.674; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:16:07.857; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:16:07.860; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:16:07.864; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:16:07.864; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:16:07.864; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:16:07.875; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 92
INFO  - 2019-11-19 15:16:07.877; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:16:07.877; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:16:09.509; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:16:11.373; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5318 ms
INFO  - 2019-11-19 15:16:11.436; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 15:16:12.554; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 15:16:13.222; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1786 ms
INFO  - 2019-11-19 15:16:22.303; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:16:22.308; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:16:22.310; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:16:32.714; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:16:33.068; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:16:34.241; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:16:36.679; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:16:36.738; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:16:36.738; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:16:36.743; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:16:37.811; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:16:37.814; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:16:37.817; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:16:37.818; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:16:37.818; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:16:37.838; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 94
INFO  - 2019-11-19 15:16:37.840; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:16:37.840; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:16:41.333; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
ERROR - 2019-11-19 15:16:45.631; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatThread; [Consumer clientId=consumer-1, groupId=test-consumer-group] Heartbeat thread failed due to unexpected error
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at org.apache.kafka.common.network.KafkaChannel.hashCode(KafkaChannel.java:367)
	at java.util.HashMap.hash(HashMap.java:338)
	at java.util.HashMap.containsKey(HashMap.java:595)
	at java.util.HashSet.contains(HashSet.java:203)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:558)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:496)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:425)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:271)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.pollNoWakeup(ConsumerNetworkClient.java:310)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatThread.run(AbstractCoordinator.java:1020)
ERROR - 2019-11-19 15:16:45.639; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: null
java.lang.RuntimeException: java.lang.OutOfMemoryError: GC overhead limit exceeded
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatThread.run(AbstractCoordinator.java:1087)
Caused by: java.lang.OutOfMemoryError: GC overhead limit exceeded
	at org.apache.kafka.common.network.KafkaChannel.hashCode(KafkaChannel.java:367)
	at java.util.HashMap.hash(HashMap.java:338)
	at java.util.HashMap.containsKey(HashMap.java:595)
	at java.util.HashSet.contains(HashSet.java:203)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:558)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:496)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:425)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:271)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.pollNoWakeup(ConsumerNetworkClient.java:310)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatThread.run(AbstractCoordinator.java:1020)
WARN  - 2019-11-19 15:16:54.932; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleRepository': Cannot resolve reference to bean 'elasticsearchTemplate' while setting bean property 'elasticsearchOperations'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'elasticsearchTemplate' defined in class path resource [es.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.elasticsearch.core.ElasticsearchTemplate]: Constructor threw exception; nested exception is java.lang.OutOfMemoryError: GC overhead limit exceeded
INFO  - 2019-11-19 15:16:54.933; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:18:01.021; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:18:01.317; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:18:01.632; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:18:02.888; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:18:02.967; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:18:02.968; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:18:02.977; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:18:03.188; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:18:03.191; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:18:03.194; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:18:03.194; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:18:03.195; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:18:03.206; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 96
INFO  - 2019-11-19 15:18:03.208; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:18:03.208; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:18:04.675; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:18:06.219; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5195 ms
INFO  - 2019-11-19 15:18:06.363; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 15:18:06.735; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 15:18:07.071; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 708 ms
INFO  - 2019-11-19 15:18:27.861; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:18:27.868; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:18:27.870; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:18:30.447; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:18:30.625; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:18:30.999; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:18:31.893; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:18:31.957; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:18:31.957; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:18:31.963; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:18:32.181; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:18:32.183; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:18:32.186; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:18:32.186; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:18:32.186; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:18:32.201; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 98
INFO  - 2019-11-19 15:18:32.203; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:18:32.203; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:18:33.490; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:18:34.517; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4068 ms
INFO  - 2019-11-19 15:18:34.609; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 15:18:35.012; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 15:18:35.323; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 714 ms
INFO  - 2019-11-19 15:40:50.453; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-19 15:40:59.857; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 16:09:21.217; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-19 16:09:22.120; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 16:17:52.362; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 16:17:52.370; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 16:17:52.372; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 16:17:55.371; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 16:17:55.573; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 16:17:55.948; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 16:17:57.290; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 16:17:57.411; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 16:17:57.411; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 16:17:57.424; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 16:17:57.628; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 16:17:57.633; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 16:17:57.639; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 16:17:57.640; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 16:17:57.641; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 16:17:57.660; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 100
INFO  - 2019-11-19 16:17:57.662; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 16:17:57.663; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 16:17:59.285; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 16:18:00.436; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5063 ms
INFO  - 2019-11-19 16:18:00.519; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 16:18:00.876; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 16:18:01.201; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 681 ms
INFO  - 2019-11-19 16:19:06.787; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 16:19:06.792; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 16:19:06.793; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 16:19:10.158; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 16:19:10.301; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 16:19:10.617; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 16:19:11.451; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 16:19:11.524; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 16:19:11.524; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 16:19:11.531; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 16:19:11.676; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 16:19:11.680; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 16:19:11.683; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 16:19:11.683; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 16:19:11.683; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 16:19:11.693; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 102
INFO  - 2019-11-19 16:19:11.694; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 16:19:11.695; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 16:19:13.041; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 16:19:14.249; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4089 ms
INFO  - 2019-11-19 16:19:14.321; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 16:19:14.650; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 16:19:14.928; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 606 ms
INFO  - 2019-11-19 16:19:21.519; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 16:19:21.525; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 16:19:21.527; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 16:19:26.272; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 16:19:26.447; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 16:19:26.744; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 16:19:27.595; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 16:19:27.652; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 16:19:27.652; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 16:19:27.658; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 16:19:27.798; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 16:19:27.801; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 16:19:27.805; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 16:19:27.807; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 16:19:27.807; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 16:19:27.818; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 104
INFO  - 2019-11-19 16:19:27.820; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 16:19:27.820; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 16:19:29.187; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 16:19:30.559; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4284 ms
INFO  - 2019-11-19 16:19:30.630; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 16:19:30.982; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 16:19:31.285; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 654 ms
INFO  - 2019-11-19 16:19:58.211; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 16:19:58.220; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 16:19:58.222; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 16:20:04.889; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 16:20:05.091; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 16:20:05.379; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 16:20:06.595; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 16:20:06.679; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 16:20:06.679; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 16:20:06.685; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 16:20:06.870; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 16:20:06.873; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 16:20:06.877; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 16:20:06.877; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 16:20:06.878; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 16:20:06.887; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 106
INFO  - 2019-11-19 16:20:06.890; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 16:20:06.890; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 16:20:08.541; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 16:20:10.576; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5685 ms
INFO  - 2019-11-19 16:20:10.652; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 16:20:11.038; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 16:20:11.590; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 938 ms
INFO  - 2019-11-19 16:20:21.292; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 16:20:21.297; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 16:20:21.298; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:20:07.585; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:20:07.995; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:20:08.407; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:20:09.758; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:20:10.049; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:20:10.049; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:20:10.055; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:20:12.149; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:20:13.567; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:20:13.681; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6053 ms
INFO  - 2019-11-20 08:20:13.874; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:20:13.990; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:20:13.995; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:20:13.996; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:20:13.996; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:20:14.550; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:20:15.092; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1217 ms
INFO  - 2019-11-20 08:20:18.419; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 108
INFO  - 2019-11-20 08:20:18.421; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:20:18.422; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:20:37.226; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-20 08:22:58.091; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:22:58.227; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:22:58.228; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:22:59.274; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-20 08:23:01.157; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:23:01.448; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:23:01.809; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:23:03.074; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:23:03.166; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:23:03.166; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:23:03.172; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:23:03.476; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:23:03.481; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:23:03.488; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:23:03.489; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:23:03.489; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:23:03.506; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 110
INFO  - 2019-11-20 08:23:03.508; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:23:03.508; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:23:05.167; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:23:06.629; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5470 ms
INFO  - 2019-11-20 08:23:06.705; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:23:07.157; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:23:07.698; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 993 ms
INFO  - 2019-11-20 08:27:20.099; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-20 08:29:12.038; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:29:12.047; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:29:12.048; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:29:13.983; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-20 08:29:16.105; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:29:16.357; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:29:16.739; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:29:17.905; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:29:18.040; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:29:18.041; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:29:18.047; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:29:18.274; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:29:18.280; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:29:18.285; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:29:18.285; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:29:18.285; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:29:18.356; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 112
INFO  - 2019-11-20 08:29:18.361; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:29:18.361; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:29:20.059; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:29:21.811; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5703 ms
INFO  - 2019-11-20 08:29:21.944; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:29:23.019; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:29:23.461; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1516 ms
INFO  - 2019-11-20 08:29:40.875; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:29:40.891; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:29:40.895; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:29:44.194; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:29:44.451; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:29:44.827; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:29:46.154; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:29:46.233; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:29:46.233; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:29:46.238; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:29:46.447; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:29:46.449; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:29:46.453; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:29:46.453; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:29:46.454; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:29:46.470; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 114
INFO  - 2019-11-20 08:29:46.472; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:29:46.472; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:29:48.084; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:29:49.279; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5082 ms
INFO  - 2019-11-20 08:29:49.356; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:29:49.734; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:29:50.100; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 744 ms
INFO  - 2019-11-20 08:29:52.577; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:29:52.582; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:29:52.583; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:29:56.099; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:29:56.264; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:29:56.602; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:29:57.735; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:29:57.803; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:29:57.805; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:29:57.816; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:29:57.991; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:29:57.997; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:29:58.003; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:29:58.003; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:29:58.003; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:29:58.020; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 116
INFO  - 2019-11-20 08:29:58.022; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:29:58.022; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:29:59.671; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:30:01.483; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5382 ms
INFO  - 2019-11-20 08:30:01.619; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:30:02.587; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:30:03.113; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1494 ms
INFO  - 2019-11-20 08:30:21.352; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:30:21.359; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:30:21.361; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:30:25.630; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:30:26.282; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:30:26.672; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:30:27.877; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:30:27.999; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:30:27.999; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:30:28.010; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:30:28.287; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:30:28.290; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:30:28.294; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:30:28.295; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:30:28.295; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:30:28.310; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 118
INFO  - 2019-11-20 08:30:28.312; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:30:28.313; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:30:30.202; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:30:31.492; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5857 ms
INFO  - 2019-11-20 08:30:31.607; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:30:38.003; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:30:38.373; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 6766 ms
INFO  - 2019-11-20 08:30:53.319; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:30:53.333; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:30:53.335; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:31:04.291; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:31:04.503; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:31:05.479; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:31:06.908; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:31:06.994; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:31:06.995; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:31:07.002; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:31:07.223; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:31:07.226; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:31:07.230; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:31:07.230; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:31:07.231; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:31:07.252; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 120
INFO  - 2019-11-20 08:31:07.255; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:31:07.255; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:31:09.951; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:31:12.423; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 8130 ms
INFO  - 2019-11-20 08:31:13.339; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:31:13.901; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:31:26.043; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 12703 ms
INFO  - 2019-11-20 08:31:29.598; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:31:29.604; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:31:29.605; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:35:19.147; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:35:19.563; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:35:20.022; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:35:21.936; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:35:22.106; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:35:22.107; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:35:22.115; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:35:22.412; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:35:22.421; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:35:22.431; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:35:22.432; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:35:22.432; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:35:22.478; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 122
INFO  - 2019-11-20 08:35:22.479; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:35:22.480; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:35:24.267; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:35:26.182; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7030 ms
INFO  - 2019-11-20 08:35:26.315; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:35:26.907; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:35:27.355; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1040 ms
INFO  - 2019-11-20 08:35:35.216; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-20 08:36:30.326; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:36:30.336; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:36:30.338; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:36:32.011; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-20 08:36:33.558; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:36:34.071; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:36:34.461; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:36:35.606; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:36:35.732; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:36:35.732; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:36:35.749; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:36:35.972; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:36:35.975; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:36:35.979; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:36:35.980; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:36:35.980; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:36:36.013; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 124
INFO  - 2019-11-20 08:36:36.017; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:36:36.018; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:36:37.726; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:36:39.023; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5462 ms
INFO  - 2019-11-20 08:36:39.145; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:36:39.627; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:36:39.982; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 837 ms
INFO  - 2019-11-20 08:36:48.580; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-20 08:40:41.557; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:40:41.564; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:40:41.566; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:40:43.380; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-20 08:40:44.609; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:40:44.770; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:40:45.066; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:40:45.956; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:40:46.015; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:40:46.016; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:40:46.021; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:40:46.215; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:40:46.218; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:40:46.221; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:40:46.221; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:40:46.221; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:40:46.237; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 126
INFO  - 2019-11-20 08:40:46.238; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:40:46.239; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:40:47.759; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:40:48.703; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4092 ms
INFO  - 2019-11-20 08:40:48.771; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:40:49.103; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:40:49.371; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 600 ms
INFO  - 2019-11-20 08:41:28.083; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:41:28.091; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:41:28.092; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:41:31.069; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:41:31.213; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:41:31.510; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:41:32.331; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:41:32.406; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:41:32.406; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:41:32.412; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:41:32.606; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:41:32.608; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:41:32.612; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:41:32.612; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:41:32.612; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:41:32.670; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 128
INFO  - 2019-11-20 08:41:32.672; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:41:32.672; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:41:34.043; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:41:35.270; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4198 ms
INFO  - 2019-11-20 08:41:35.354; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:41:35.784; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:41:36.128; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 774 ms
INFO  - 2019-11-20 08:41:52.921; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:41:52.926; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:41:52.928; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:41:56.967; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:41:57.157; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:41:57.527; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:41:58.415; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:41:58.515; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:41:58.515; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:41:58.522; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:41:58.718; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:41:58.720; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:41:58.723; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:41:58.723; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:41:58.723; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:41:58.733; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 130
INFO  - 2019-11-20 08:41:58.734; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:41:58.734; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:42:00.224; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:42:01.417; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4447 ms
INFO  - 2019-11-20 08:42:01.501; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:42:01.837; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:42:02.132; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 631 ms
INFO  - 2019-11-20 08:42:15.284; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:42:15.292; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:42:15.294; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:42:20.413; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:42:20.642; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:42:20.960; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:42:22.092; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:42:22.437; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:42:22.437; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:42:22.444; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:42:22.584; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:42:22.586; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:42:22.590; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:42:22.590; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:42:22.590; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:42:22.603; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 132
INFO  - 2019-11-20 08:42:22.605; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:42:22.605; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:42:24.582; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:42:28.407; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7991 ms
INFO  - 2019-11-20 08:42:28.487; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:42:29.046; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:42:40.091; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 11603 ms
INFO  - 2019-11-20 08:42:59.810; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:43:00.121; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:43:00.443; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:43:01.686; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:43:01.795; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:43:01.796; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:43:01.803; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:43:01.999; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:43:02.002; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:43:02.006; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:43:02.006; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:43:02.006; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:43:02.029; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 134
INFO  - 2019-11-20 08:43:02.031; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:43:02.031; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:43:03.570; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:43:04.803; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4989 ms
INFO  - 2019-11-20 08:43:04.896; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:43:05.268; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:43:05.622; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 725 ms
INFO  - 2019-11-20 08:43:11.283; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-20 08:43:31.235; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:43:31.242; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:43:31.243; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:43:33.054; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-20 08:43:34.536; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:43:34.776; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:43:35.153; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:43:36.211; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:43:36.290; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:43:36.291; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:43:36.299; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:43:36.499; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:43:36.502; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:43:36.506; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:43:36.506; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:43:36.507; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:43:36.559; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 136
INFO  - 2019-11-20 08:43:36.561; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:43:36.561; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:43:38.106; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:43:39.187; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4648 ms
INFO  - 2019-11-20 08:43:39.264; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:43:39.664; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:43:39.971; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 707 ms
INFO  - 2019-11-20 08:43:49.274; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-20 08:45:10.443; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:45:10.450; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:45:10.451; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:45:11.621; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-20 08:45:12.870; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:45:13.107; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:45:13.535; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:45:14.498; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:45:14.606; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:45:14.606; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:45:14.621; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:45:15.069; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:45:15.071; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:45:15.073; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:45:15.074; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:45:15.074; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:45:15.086; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 138
INFO  - 2019-11-20 08:45:15.088; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:45:15.088; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:45:16.479; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:45:17.417; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4544 ms
INFO  - 2019-11-20 08:45:17.507; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:45:17.903; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:45:18.167; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 660 ms
INFO  - 2019-11-20 08:45:26.849; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-20 09:55:52.942; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2019-11-20 09:55:52.967; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@59e5ddf, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@536aaa8d, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@e320068, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1f57539, org.springframework.test.context.transaction.TransactionalTestExecutionListener@76f2b07d, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@704a52ec]
INFO  - 2019-11-20 09:55:53.365; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 09:55:54.027; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 09:55:55.164; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 09:55:55.260; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 09:55:55.261; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 09:55:55.268; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 09:55:55.454; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 09:55:55.456; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 09:55:55.459; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 09:55:55.459; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 09:55:55.460; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 09:55:57.869; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2019-11-20 09:55:57.873; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [articles-0]
INFO  - 2019-11-20 09:55:57.873; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [articles-0]
INFO  - 2019-11-20 09:55:57.873; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 09:55:57.926; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 139
INFO  - 2019-11-20 09:55:57.927; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2019-11-20 09:55:57.928; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2019-11-20 09:56:23.901; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 09:56:24.212; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 09:56:24.597; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 09:56:25.979; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 09:56:26.084; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 09:56:26.084; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 09:56:26.096; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 09:56:26.300; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 09:56:26.304; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 09:56:26.309; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 09:56:26.310; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 09:56:26.311; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 09:56:26.330; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 141
INFO  - 2019-11-20 09:56:26.333; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 09:56:26.333; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 09:56:28.127; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 09:56:29.520; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5615 ms
INFO  - 2019-11-20 09:56:29.630; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 09:56:30.044; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 09:56:30.437; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 806 ms
INFO  - 2019-11-20 09:56:30.907; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-20 10:03:04.612; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 10:03:04.629; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 10:03:04.631; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 10:03:05.851; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-20 10:03:07.496; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 10:03:07.691; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 10:03:08.014; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 10:03:08.999; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 10:03:09.080; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 10:03:09.081; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 10:03:09.089; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 10:03:09.303; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 10:03:09.305; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 10:03:09.308; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 10:03:09.308; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 10:03:09.309; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 10:03:09.319; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 143
INFO  - 2019-11-20 10:03:09.321; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 10:03:09.321; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 10:03:10.696; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 10:03:11.903; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4405 ms
INFO  - 2019-11-20 10:03:11.991; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 10:03:12.356; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 10:03:12.622; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 631 ms
INFO  - 2019-11-20 10:33:21.682; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-20 10:33:26.795; org.apache.kafka.clients.FetchSessionHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 0: org.apache.kafka.common.errors.DisconnectException.
INFO  - 2019-11-20 10:33:26.883; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 10:33:58.540; org.apache.kafka.clients.FetchSessionHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 0: org.apache.kafka.common.errors.DisconnectException.
INFO  - 2019-11-20 10:46:21.967; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-20 10:46:33.336; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 10:51:09.818; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 10:51:10.208; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 10:51:10.573; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 10:51:12.072; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 10:51:12.167; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 10:51:12.167; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 10:51:12.178; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 10:51:12.413; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 10:51:12.417; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 10:51:12.424; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 10:51:12.424; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 10:51:12.424; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 10:51:12.466; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 145
INFO  - 2019-11-20 10:51:12.468; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 10:51:12.468; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 10:51:14.223; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 10:51:15.848; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6025 ms
INFO  - 2019-11-20 10:51:15.942; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 10:51:16.337; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 10:51:16.645; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 703 ms
INFO  - 2019-11-20 10:51:17.112; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
ERROR - 2019-11-20 11:07:52.019; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = articles, partition = 0, offset = 2058, CreateTime = 1574219271370, serialized key size = -1, serialized value size = 9424, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"categoryId":2,"channelId":1,"content":"00   | Lexie  |   50 ZAO32MT 11 00 00App Monkey 00Monkey16Ben Pasternak 175App StoreTop 30 Monkey15 Ben00 Monkey200  HollaBen  tbh Gossip Girl tbh (to be honest)  tbhInstagramtbhInstagram 20178tbhApp Store500250Facebook FacebookSnapchat 18Facebooktbh app Islands Islandsapp16Greg Isenberg5byStumbleUpon 5byGreg23 Gregislands islands 6 GregWeWork WeWorkIslands WeWorkIslands  00app 1 MonkeyMonkey MonkeyMonkey  2 tbh 00   3 Moneky App app  App 00 PRWeek72%29% 002020Facebook00 1 IslandsAminoInstagram   2 InstagramPinterest Sparks and Honey008 MonkeyTik Tok 3FOMO Fear Of Missing Out FOMO tbh  00   -END- ","contentType":0,"created":1574219271370,"deleted":0,"hits":0,"hot":1,"keywords":"","original":"","status":1,"title":"00","userId":155})
org.springframework.jdbc.UncategorizedSQLException: 
### Error updating database.  Cause: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1
### The error may involve com.liujian.cms.dao.ArticleMapper.insertSelective-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article      ( title,                              channel_id,                       category_id,                       user_id,                       hits,                       hot,                       status,                       deleted,                       created,                              content,                               content_type,                          keywords,                          original )       values ( ?,                              ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                              ?,                               ?,                       ?,                          ? )
### Cause: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1
; uncategorized SQLException; SQL state [HY000]; error code [1366]; Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1; nested exception is java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:89)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy40.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy41.insertSelective(Unknown Source)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:47)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:30)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1055)
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:956)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3491)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy81.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 15 more
ERROR - 2019-11-20 11:07:52.322; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = articles, partition = 0, offset = 2101, CreateTime = 1574219272167, serialized key size = -1, serialized value size = 1147, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"categoryId":2,"channelId":1,"content":"Facebook  WhatsAppInstagram  Facebook Pay Facebook  Facebook Pay  FacebookMessengerInstagram  WhatsApp Facebook  Calibra  Libra   Facebook  Messenger  Facebook  Facebook Pay Facebook Pay  Instagram  WhatsApp  Facebook  Deborah Liu  Facebook  Facebook Pay  ","contentType":0,"created":1574219272166,"deleted":0,"hits":0,"hot":1,"keywords":"","original":"","status":1,"title":"Facebook  WhatsAppInstagram  Facebook Pay","userId":155})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.liujian.cms.dao.ArticleMapper.insertSelective-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article      ( title,                              channel_id,                       category_id,                       user_id,                       hits,                       hot,                       status,                       deleted,                       created,                              content,                               content_type,                          keywords,                          original )       values ( ?,                              ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                              ?,                               ?,                       ?,                          ? )
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy40.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy41.insertSelective(Unknown Source)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:47)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:30)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor195.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy81.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor194.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 15 more
ERROR - 2019-11-20 11:07:52.858; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = articles, partition = 0, offset = 2142, CreateTime = 1574219272818, serialized key size = -1, serialized value size = 19187, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"categoryId":2,"channelId":1,"content":" X 2011 20092013  1116 MDMA     MDMA    MDMALSD   MDMA 2007      24   2 Stardust Stardust   2008kanebo 20071128Destination Nowhere 2008COFFRET D'OR Stardust 20091 2009930Stardust 2012 2009910Stardust  2009823  20099StardustFK  instructorSergioSergio Sergio   20131320104 AvexAvex SNS AvexAvex  2012  2012  201939ERIKAFreePV  2007Erika 2007 0822 CMBeeTVNHK 2012     A2011 A2015AvexACEOMindfulness AAAvex 2012 7instructorSergio Sergio2010Sergio SergioSergio SergioSergio Sergio Sergio Sergio50facebook Sergio          99  Pacchigi!6  erika2007          33  cj10141234 ","contentType":0,"created":1574219272818,"deleted":0,"hits":0,"hot":1,"keywords":"","original":"","status":1,"title":"","userId":155})
org.springframework.jdbc.UncategorizedSQLException: 
### Error updating database.  Cause: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 \xE4...' for column 'content' at row 1
### The error may involve com.liujian.cms.dao.ArticleMapper.insertSelective-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article      ( title,                              channel_id,                       category_id,                       user_id,                       hits,                       hot,                       status,                       deleted,                       created,                              content,                               content_type,                          keywords,                          original )       values ( ?,                              ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                              ?,                               ?,                       ?,                          ? )
### Cause: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 \xE4...' for column 'content' at row 1
; uncategorized SQLException; SQL state [HY000]; error code [1366]; Incorrect string value: '\xF0\x9F\x91\x87 \xE4...' for column 'content' at row 1; nested exception is java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 \xE4...' for column 'content' at row 1
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:89)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy40.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy41.insertSelective(Unknown Source)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:47)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:30)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 \xE4...' for column 'content' at row 1
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1055)
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:956)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3491)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor195.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy81.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor194.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 15 more
ERROR - 2019-11-20 11:07:57.386; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = articles, partition = 0, offset = 2424, CreateTime = 1574219277306, serialized key size = -1, serialized value size = 13765, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"categoryId":2,"channelId":1,"content":" | 1200 2018QQ 1200 LPR 1119500120072.50%1912001120LPRMLFLPR  202018QQ 31.52%201820%   3 app1120312 3-4 203-45%2% 171 Wind1119A171100%A  112010 Q318.672% 18.672%BNon-GAAP3.42.461B1.2838%43%1.14B124%795   5G12  5G5G11195G12 A 19A5GA  1000 10  111910AAA100 2019Q3 2019201915.12435.0%5.985  11181129 WeWork WeWorkWeWork4000 20193320 192019201883320100050%1489 167704 1-101677043.8%806624.4%870423.3%1415140.4%1-90.8  90 10 201910975610067311138014244410  1920191119M2 101.3 1035.992326.21.3PSL IPO  C C2016POCT C CMCCMC Capital5CCMC EasyStack EasyStackPKPKCEasyStack20142 VPhotoB1 VPhotoB1VPhoto472VPhotoTo B 202018QQ  ","contentType":0,"created":1574219277306,"deleted":0,"hits":0,"hot":1,"keywords":"","original":"","status":1,"title":"  1200","userId":155})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.liujian.cms.dao.ArticleMapper.insertSelective-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article      ( title,                              channel_id,                       category_id,                       user_id,                       hits,                       hot,                       status,                       deleted,                       created,                              content,                               content_type,                          keywords,                          original )       values ( ?,                              ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                              ?,                               ?,                       ?,                          ? )
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy40.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy41.insertSelective(Unknown Source)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:47)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:30)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor195.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy81.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor194.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 15 more
ERROR - 2019-11-20 11:07:57.473; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = articles, partition = 0, offset = 2434, CreateTime = 1574219277414, serialized key size = -1, serialized value size = 12917, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"categoryId":2,"channelId":1,"content":"  2019.11.8  01    02  1171.31203500PreneticsWeLab  03  30ApolloApollo114  04     05 AI 117AI  06 vivo5GX30 117vivo5G AI5GExynos 980vivo X3012vivovivo2-35G  07  1CC 9 ProDXOMARK121Mate 30 Pro30%  01  117Bill Gates19982000Windows MobileDealBook ConferenceAndroid4000  02 SpaceX200 117SpaceX(Elon Musk)Starship200SpaceX9  03 ASML 117NIKKEIASML41.2EUV2020ASMLEUVASMLASMLEUVexport licenseASML  04 109.5 10148(9.5)10  05  Maruti Suzuki Toyotsu India Private LimitedMaruti Suzuki50MSTI2000   01 500Pre-A Pre-A2017+10 500  3000 25%4.1/ 36 02 MCN A+   & MCN A+ TOPIC10 A 2017  3 +MCNKOL--- 36 03 A+ A+  04 BitMax BTMX.com(BitMax.io)BTMX.comBitMax.io  05 A A20184.0BioTrack Capital2017  06   7 2018 2019  twosigma   ","contentType":0,"created":1574219277414,"deleted":0,"hits":0,"hot":1,"keywords":"","original":"","status":1,"title":" ","userId":155})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.liujian.cms.dao.ArticleMapper.insertSelective-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article      ( title,                              channel_id,                       category_id,                       user_id,                       hits,                       hot,                       status,                       deleted,                       created,                              content,                               content_type,                          keywords,                          original )       values ( ?,                              ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                              ?,                               ?,                       ?,                          ? )
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy40.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy41.insertSelective(Unknown Source)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:47)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:30)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor195.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy81.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor194.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 15 more
ERROR - 2019-11-20 11:07:58.442; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = articles, partition = 0, offset = 2488, CreateTime = 1574219278090, serialized key size = -1, serialized value size = 3462, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"categoryId":2,"channelId":1,"content":"     zui  zui 3 1  2  zui   2010          C 100gC62  7-8 3-5zui    1.3-5 2.  10-20    | ","contentType":0,"created":1574219278090,"deleted":0,"hits":0,"hot":1,"keywords":"","original":"","status":1,"title":"","userId":155})
org.springframework.jdbc.UncategorizedSQLException: 
### Error updating database.  Cause: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1
### The error may involve com.liujian.cms.dao.ArticleMapper.insertSelective-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article      ( title,                              channel_id,                       category_id,                       user_id,                       hits,                       hot,                       status,                       deleted,                       created,                              content,                               content_type,                          keywords,                          original )       values ( ?,                              ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                              ?,                               ?,                       ?,                          ? )
### Cause: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1
; uncategorized SQLException; SQL state [HY000]; error code [1366]; Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1; nested exception is java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:89)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy40.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy41.insertSelective(Unknown Source)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:47)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:30)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1055)
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:956)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3491)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor195.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy81.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor194.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 15 more
ERROR - 2019-11-20 11:07:58.533; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = articles, partition = 0, offset = 2499, CreateTime = 1574219278225, serialized key size = -1, serialized value size = 10406, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"categoryId":2,"channelId":1,"content":" 3  IPO  176   9  3  11  19  App  11  20  3   12  11  20  9:0011  29  9:00   5:00-20:0050   IPO  176   11  20  IPO  176   15  9988 5  0.125  188  4.875  20   CEO  2020  10  5G  11  19  5G  5G  12  Redmi K30 10  5G   AIoT  2200+ AIoT  1.96 36Kr  90   NPR 18  90  5  NPR   500  11  19  500  4    Teams  2000  Slack 11  20  CNBC  Teams  2000  54 SlackSlack  10  1200  Slack  10 8.4 6  18 50  1  C2M  11  19  2019  CEO  C2M  75% 67% C2M  70%36Kr  11  23  11  19  CEO  11  23 30  App   11  12  1000   Model 3  35.58   Model 3  11  22  35.58  tesla.cn  Model 3  460 NEDC 0-100 / 5.6  225 /  CEO Faraday FutureCEO  11  20  FF   4.02020  11  19 X  4.0  2020   4.0  L4  1024  350kg 150kg km/h 100km 30%DoNews Oculus Link Beta  11  19 Oculus  Oculus Link Beta  USB Type C  PC PC VR Quest  Rift   OC6 Oculus  79  Anker Powerline USB-C  USB 3.03  AK-A8167011 13   11  19   1000   2018  12  2020  4   11  19  CTO  CNBC East Tech West App   65%   2012  5.5 2016  Uber  ","contentType":0,"created":1574219278225,"deleted":0,"hits":0,"hot":1,"keywords":"","original":"","status":1,"title":" 3  IPO  176 ","userId":155})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.liujian.cms.dao.ArticleMapper.insertSelective-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article      ( title,                              channel_id,                       category_id,                       user_id,                       hits,                       hot,                       status,                       deleted,                       created,                              content,                               content_type,                          keywords,                          original )       values ( ?,                              ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                              ?,                               ?,                       ?,                          ? )
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy40.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy41.insertSelective(Unknown Source)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:47)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:30)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor195.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy81.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor194.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 15 more
ERROR - 2019-11-20 11:07:58.551; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = articles, partition = 0, offset = 2502, CreateTime = 1574219278252, serialized key size = -1, serialized value size = 10396, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"categoryId":2,"channelId":1,"content":"Uber CEO  WeWork   5:00-20:00 11  7  5:00-20:0020:00-23:0023:00-5:00  5:00-20:00  45%  465%  4%  11  8  4%  11  7  186.66  Uber CEO  WeWork  11  7  DealBook  WeWork  WeWork Uber  Uber  2021  EBITDA   11  7  2020  50%36Kr OYO  11  7 OYOOYO  OYO  7 PMSOYO  OYO  B UP  11  7  B  UP  A-B B   26  4500  4500 B  A-  Juul  11  8  Juul Labs  10  12  40%   11  7 5G  ARM  PC   42  11  7  42  10% MSCI  6 30%36Kr  11  7  2020  5  31 2016  1  9  4-12  8  1  COO   9  11  8  9   11  7  8    App 11  7  App 2019  11  6  1.0 // vivo  5G AI Exynos 980 11  7 vivo  5G AI Exynos 980Exynos 980  NSA  SA Exynos 980  5G  Sub-6GHz  2.55Gbps  4G-5G E-UTRA-NR Dual Connectivity, EN-DC 3.55Gbps Exynos980  ARM  Cortex-A77 CPU  Cortex-A76  20% GPU Mali-G76Exynos 980  NPU  DSP  ISP 1.08  NPU PingWest  11  7 2019  AI  All in AI    ","contentType":0,"created":1574219278252,"deleted":0,"hits":0,"hot":1,"keywords":"","original":"","status":1,"title":"Uber CEO  WeWork ","userId":155})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.liujian.cms.dao.ArticleMapper.insertSelective-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article      ( title,                              channel_id,                       category_id,                       user_id,                       hits,                       hot,                       status,                       deleted,                       created,                              content,                               content_type,                          keywords,                          original )       values ( ?,                              ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                              ?,                               ?,                       ?,                          ? )
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy40.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy41.insertSelective(Unknown Source)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:47)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:30)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor195.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy81.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor194.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 15 more
INFO  - 2019-11-20 11:35:34.101; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-20 11:35:38.607; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 12:57:19.121; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-20 12:57:21.665; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 15:01:44.029; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-20 15:01:44.380; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-21 08:25:30.994; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-21 08:25:31.415; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-21 08:25:31.836; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-21 08:25:33.526; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-21 08:25:33.637; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-21 08:25:33.638; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-21 08:25:33.654; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-21 08:25:33.929; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-21 08:25:33.932; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-21 08:25:33.937; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-21 08:25:33.938; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-21 08:25:33.939; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-21 08:25:35.763; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 182
INFO  - 2019-11-21 08:25:35.765; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2019-11-21 08:25:35.766; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2019-11-21 08:25:35.825; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
ERROR - 2019-11-21 08:25:38.703; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{LvBGNh_QQMu-iC5TXMJ8JQ}{192.168.18.130}{192.168.18.130:9300}]
INFO  - 2019-11-21 08:25:39.642; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 8628 ms
INFO  - 2019-11-21 08:25:39.856; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-21 08:25:40.424; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-21 08:25:40.984; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1127 ms
INFO  - 2019-11-21 08:25:59.036; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-21 08:32:14.897; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
WARN  - 2019-11-21 08:32:16.956; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:19.113; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:21.371; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:23.756; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:26.482; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:29.480; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:32.474; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:35.670; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:38.741; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:41.860; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:44.722; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:47.741; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:50.960; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:53.788; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:56.874; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:59.748; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:02.920; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:05.813; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:08.725; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:11.746; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:14.604; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:17.512; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:20.673; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:23.736; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:26.598; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:29.575; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:32.766; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:35.933; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:38.914; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:41.771; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:44.977; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:48.026; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:51.206; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:54.139; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:57.267; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:00.256; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:03.141; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:06.084; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:08.967; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:12.137; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:15.250; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:18.264; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:21.336; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:24.506; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:27.574; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:30.741; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:33.753; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:36.815; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:39.932; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:43.004; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:46.067; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:49.183; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:52.356; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:55.517; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:58.426; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:01.638; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:04.647; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:07.508; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:10.419; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:13.480; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:16.545; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:19.559; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:22.570; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:25.582; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:28.443; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:31.458; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:34.519; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:37.441; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:40.350; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:43.210; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:46.067; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:48.931; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:51.839; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:54.748; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:57.577; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:00.736; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:03.748; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:06.808; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:10.022; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:13.189; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:16.266; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:19.255; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:22.474; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:25.492; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:28.356; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:31.494; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:34.663; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:37.577; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:40.742; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:43.608; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:46.518; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:49.375; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:52.589; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:55.801; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:58.861; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:01.876; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:04.886; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:08.099; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:11.267; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:14.383; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:17.354; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:20.425; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:23.384; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:26.496; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:29.712; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:32.623; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:35.756; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:38.727; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:41.633; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:44.801; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:47.971; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:50.837; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:53.705; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:56.917; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:59.928; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:02.940; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:05.850; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:08.764; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:11.881; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:15.099; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:18.166; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:21.327; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
INFO  - 2019-11-21 08:38:42.637; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-21 08:38:42.873; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-21 08:38:43.179; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-21 08:38:44.331; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-21 08:38:44.419; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-21 08:38:44.420; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-21 08:38:44.430; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-21 08:38:46.081; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
WARN  - 2019-11-21 08:38:46.606; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2019-11-21 08:38:47.688; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5048 ms
INFO  - 2019-11-21 08:38:47.772; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-21 08:38:48.087; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-21 08:38:48.386; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 614 ms
WARN  - 2019-11-21 08:38:48.682; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:50.851; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:53.081; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:55.438; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:58.351; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:01.420; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:04.636; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:07.851; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2019-11-21 08:39:10.651; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2019-11-21 08:39:11.015; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:14.083; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:17.064; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:20.029; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:22.941; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:25.911; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:28.920; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:32.031; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:35.242; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:38.160; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:41.276; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:44.188; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:47.154; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:50.122; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:53.331; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:56.344; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:59.257; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:02.315; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:05.276; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:08.335; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:11.449; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:14.559; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:17.669; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:20.841; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:24.071; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:26.932; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:29.997; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:33.068; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:36.292; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:39.416; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:42.429; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:45.646; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:48.757; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:51.664; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:54.775; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:57.650; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:00.683; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:03.903; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:06.816; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:09.676; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:12.838; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:15.694; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:18.856; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:22.018; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:24.935; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:27.865; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:30.731; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:33.593; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:36.504; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:39.519; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:42.381; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:45.490; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:48.507; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:51.415; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:54.379; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:57.395; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:00.517; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:03.574; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:06.536; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:09.395; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:12.263; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:15.428; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:18.290; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:21.253; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:24.119; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:27.286; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:30.460; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:33.622; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:36.529; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:39.643; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:42.804; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:45.760; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:48.719; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:51.933; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:55.096; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:58.010; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:01.133; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:04.249; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:07.256; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:10.164; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:13.171; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:16.179; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:19.216; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:22.377; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:25.249; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:28.074; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:31.086; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:33.996; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:37.060; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:40.067; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:42.977; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:46.183; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:49.294; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:52.310; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:55.438; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:58.521; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:01.457; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:04.582; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:07.445; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:10.366; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:13.286; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:16.450; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:19.314; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:22.290; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:25.307; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:28.524; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:31.745; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:34.810; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:37.886; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:40.745; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:43.809; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:46.976; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:50.089; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:53.006; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:55.974; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:59.152; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:02.067; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:05.233; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:08.347; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:11.360; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:14.470; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:17.475; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:20.686; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:23.709; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:26.693; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:29.511; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:32.538; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:35.450; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:38.317; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:41.435; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:44.654; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:47.871; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:50.788; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:53.805; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:56.770; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:59.881; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:02.946; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:05.887; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:09.081; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:12.000; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:15.181; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:18.357; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:21.572; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:24.637; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:27.602; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:30.725; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:33.785; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:36.943; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:39.951; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:42.886; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:45.815; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:48.937; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:51.971; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:54.887; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:57.699; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:00.762; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:03.934; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:06.943; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:09.903; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:13.116; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:16.181; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:19.164; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:22.235; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:25.480; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:28.599; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:31.463; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:34.655; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:37.734; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:40.698; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:43.571; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:46.446; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:49.575; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:52.487; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:55.708; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:58.830; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:02.028; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:05.001; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:08.213; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:11.440; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:14.559; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:17.422; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:20.387; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:23.504; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:26.425; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:29.346; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:32.331; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:35.559; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:38.431; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:41.462; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:44.343; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:47.516; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:50.689; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:53.813; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:56.865; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:59.836; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:03.002; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:06.136; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:09.269; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:12.248; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:15.237; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2019-11-21 08:49:16.434; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2019-11-21 08:49:16.453; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@17579e0f, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4d41cee, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3712b94, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2833cc44, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33f88ab, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@27a8c74e]
INFO  - 2019-11-21 08:49:16.956; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-21 08:49:17.604; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
WARN  - 2019-11-21 08:49:18.398; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2019-11-21 08:49:18.807; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-21 08:49:18.892; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-21 08:49:18.892; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-21 08:49:18.892; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
WARN  - 2019-11-21 08:49:21.261; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:21.511; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2019-11-21 08:49:22.624; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
WARN  - 2019-11-21 08:49:23.327; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:24.400; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2019-11-21 08:49:24.563; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2019-11-21 08:49:25.446; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:27.665; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:30.090; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:32.917; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:35.787; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2019-11-21 08:49:37.894; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-21 08:49:37.896; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-21 08:49:37.897; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-21 08:49:39.144; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
