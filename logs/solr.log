INFO  - 2019-11-19 14:34:56.621; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 14:34:57.903; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 14:34:58.004; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 14:34:58.005; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 14:34:58.019; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 14:34:58.237; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 1613 ms
INFO  - 2019-11-19 14:34:58.264; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 14:34:58.267; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 14:34:58.271; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 14:34:58.271; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 14:34:58.271; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 14:34:58.314; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 14:34:58.320; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 69
INFO  - 2019-11-19 14:34:58.321; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 14:34:58.322; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 14:34:58.857; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 14:34:59.654; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1340 ms
INFO  - 2019-11-19 14:41:52.282; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 14:41:52.288; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 14:41:53.308; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 14:41:53.438; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 14:41:53.750; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 14:41:54.512; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 14:41:54.575; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 14:41:54.576; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 14:41:54.582; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 14:41:54.763; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 14:41:54.765; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 14:41:54.769; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 14:41:54.769; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 14:41:54.769; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 14:41:54.781; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 71
INFO  - 2019-11-19 14:41:54.783; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 14:41:54.783; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 14:41:56.313; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 14:42:05.937; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 12627 ms
INFO  - 2019-11-19 14:42:06.003; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 14:42:06.822; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 14:42:07.138; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1134 ms
INFO  - 2019-11-19 14:49:33.864; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-19 14:49:48.811; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 14:49:48.812; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-19 14:49:48.913; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 14:50:38.062; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 14:50:38.067; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 14:50:38.068; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 14:50:42.119; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 14:50:42.290; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 14:50:42.601; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 14:50:43.449; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 14:50:43.537; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 14:50:43.538; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 14:50:43.546; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 14:50:43.742; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 14:50:43.745; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 14:50:43.750; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 14:50:43.751; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 14:50:43.751; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 14:50:43.766; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 73
INFO  - 2019-11-19 14:50:43.769; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 14:50:43.769; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 14:50:45.139; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 14:50:46.161; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4038 ms
INFO  - 2019-11-19 14:50:46.237; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 14:50:46.578; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 14:50:46.867; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 629 ms
INFO  - 2019-11-19 14:51:19.463; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 14:51:19.468; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 14:51:19.469; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 14:51:22.628; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 14:51:22.775; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 14:51:23.133; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 14:51:24.029; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 14:51:24.111; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 14:51:24.111; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 14:51:24.118; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 14:51:24.367; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 14:51:24.370; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 14:51:24.375; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 14:51:24.375; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 14:51:24.375; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 14:51:24.406; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 75
INFO  - 2019-11-19 14:51:24.409; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 14:51:24.410; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 14:51:25.789; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 14:51:27.266; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4635 ms
INFO  - 2019-11-19 14:51:27.362; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 14:51:27.743; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 14:51:28.013; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 651 ms
INFO  - 2019-11-19 14:58:59.363; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2019-11-19 14:58:59.385; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@17579e0f, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4d41cee, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3712b94, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2833cc44, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33f88ab, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@27a8c74e]
INFO  - 2019-11-19 14:58:59.868; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 14:59:00.426; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 14:59:01.692; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 14:59:01.792; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 14:59:01.793; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 14:59:01.801; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 14:59:02.338; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 14:59:02.340; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 14:59:02.346; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 14:59:02.347; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 14:59:02.347; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 14:59:03.547; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2019-11-19 14:59:03.550; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [articles-0]
INFO  - 2019-11-19 14:59:03.550; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [articles-0]
INFO  - 2019-11-19 14:59:03.551; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 14:59:03.555; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 76
INFO  - 2019-11-19 14:59:03.556; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 14:59:03.556; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 14:59:03.584; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 76
INFO  - 2019-11-19 14:59:03.595; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2019-11-19 14:59:03.596; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2019-11-19 14:59:06.152; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 14:59:07.795; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-19 14:59:08.376; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 14:59:08.385; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 14:59:08.386; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 14:59:09.559; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2019-11-19 14:59:09.561; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [articles-0]
INFO  - 2019-11-19 14:59:09.561; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [articles-0]
INFO  - 2019-11-19 14:59:09.562; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 14:59:09.564; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 77
INFO  - 2019-11-19 14:59:09.565; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 14:59:09.565; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 14:59:09.702; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-19 15:05:03.597; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2019-11-19 15:05:03.613; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@17579e0f, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4d41cee, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3712b94, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2833cc44, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33f88ab, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@27a8c74e]
INFO  - 2019-11-19 15:05:03.880; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:05:04.202; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:05:05.231; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:05:05.299; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:05:05.300; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:05:05.306; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:05:05.507; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:05:05.509; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:05:05.512; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:05:05.512; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:05:05.512; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:05:06.628; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2019-11-19 15:05:06.630; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [articles-0]
INFO  - 2019-11-19 15:05:06.630; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [articles-0]
INFO  - 2019-11-19 15:05:06.630; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:05:06.637; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 78
INFO  - 2019-11-19 15:05:06.637; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 78
INFO  - 2019-11-19 15:05:06.638; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:05:06.638; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:05:06.638; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2019-11-19 15:05:06.638; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2019-11-19 15:05:07.605; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:05:08.946; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-19 15:05:22.674; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:05:22.682; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:05:22.683; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:05:24.173; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-19 15:05:24.641; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2019-11-19 15:05:24.812; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [articles-0]
INFO  - 2019-11-19 15:05:24.812; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [articles-0]
INFO  - 2019-11-19 15:05:24.812; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:05:24.818; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 79
INFO  - 2019-11-19 15:05:24.819; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:05:24.819; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:05:49.443; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2019-11-19 15:05:49.460; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@17579e0f, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4d41cee, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3712b94, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2833cc44, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33f88ab, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@27a8c74e]
INFO  - 2019-11-19 15:05:49.718; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:05:50.083; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:05:51.195; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:05:51.274; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:05:51.274; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:05:51.282; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:05:51.450; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:05:51.452; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:05:51.457; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:05:51.457; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:05:51.458; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:05:53.461; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:05:54.799; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-19 15:05:54.881; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 80
INFO  - 2019-11-19 15:05:54.884; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:05:54.885; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:06:01.350; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:06:01.358; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:06:01.360; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:06:02.969; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-19 15:07:51.730; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:07:52.055; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:07:52.472; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:07:53.738; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:07:53.978; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:07:53.979; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:07:53.986; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:07:54.239; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:07:54.240; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:07:54.245; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:07:54.245; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:07:54.245; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:07:54.277; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 82
INFO  - 2019-11-19 15:07:54.279; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:07:54.279; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:07:56.003; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:07:57.244; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5511 ms
INFO  - 2019-11-19 15:07:57.354; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 15:07:57.786; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 15:07:58.139; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 785 ms
INFO  - 2019-11-19 15:09:28.217; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:09:28.225; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:09:28.227; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:09:30.857; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:09:31.089; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:09:31.465; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:09:32.723; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:09:32.789; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:09:32.790; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:09:32.795; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:09:32.998; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:09:33.000; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:09:33.003; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:09:33.004; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:09:33.004; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:09:33.080; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 84
INFO  - 2019-11-19 15:09:33.082; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:09:33.082; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:09:34.238; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:09:35.211; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4351 ms
INFO  - 2019-11-19 15:09:35.281; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 15:09:35.595; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 15:09:35.906; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 625 ms
INFO  - 2019-11-19 15:09:50.325; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-19 15:13:36.598; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:13:36.603; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:13:36.605; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:13:37.786; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-19 15:13:39.317; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:13:39.493; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:13:39.815; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:13:40.728; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:13:40.809; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:13:40.809; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:13:40.815; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:13:40.999; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:13:41.001; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:13:41.005; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:13:41.006; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:13:41.006; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:13:41.021; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 86
INFO  - 2019-11-19 15:13:41.023; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:13:41.023; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:13:42.398; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:13:45.038; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5718 ms
INFO  - 2019-11-19 15:13:45.139; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 15:13:45.774; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 15:13:46.032; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 893 ms
INFO  - 2019-11-19 15:14:06.496; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-19 15:15:18.479; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:15:18.486; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:15:18.487; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:15:19.876; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-19 15:15:21.063; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:15:21.207; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:15:21.523; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:15:22.399; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:15:22.461; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:15:22.462; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:15:22.469; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:15:22.605; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:15:22.608; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:15:22.612; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:15:22.612; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:15:22.612; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:15:22.621; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 88
INFO  - 2019-11-19 15:15:22.623; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:15:22.623; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:15:23.968; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:15:25.221; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4156 ms
INFO  - 2019-11-19 15:15:25.311; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 15:15:25.712; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 15:15:25.983; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 671 ms
INFO  - 2019-11-19 15:15:48.904; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:15:48.909; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:15:48.911; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:15:52.131; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:15:52.319; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:15:52.631; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:15:53.541; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:15:53.614; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:15:53.615; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:15:53.620; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:15:53.778; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:15:53.780; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:15:53.784; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:15:53.784; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:15:53.785; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:15:53.796; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 90
INFO  - 2019-11-19 15:15:53.798; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:15:53.798; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:15:55.141; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:15:56.461; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4328 ms
INFO  - 2019-11-19 15:15:56.525; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 15:15:56.861; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 15:15:57.164; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 639 ms
INFO  - 2019-11-19 15:16:01.264; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:16:01.269; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:16:01.270; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:16:06.053; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:16:06.229; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:16:06.750; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:16:07.592; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:16:07.667; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:16:07.667; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:16:07.674; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:16:07.857; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:16:07.860; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:16:07.864; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:16:07.864; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:16:07.864; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:16:07.875; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 92
INFO  - 2019-11-19 15:16:07.877; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:16:07.877; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:16:09.509; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:16:11.373; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5318 ms
INFO  - 2019-11-19 15:16:11.436; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 15:16:12.554; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 15:16:13.222; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1786 ms
INFO  - 2019-11-19 15:16:22.303; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:16:22.308; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:16:22.310; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:16:32.714; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:16:33.068; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:16:34.241; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:16:36.679; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:16:36.738; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:16:36.738; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:16:36.743; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:16:37.811; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:16:37.814; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:16:37.817; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:16:37.818; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:16:37.818; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:16:37.838; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 94
INFO  - 2019-11-19 15:16:37.840; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:16:37.840; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:16:41.333; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
ERROR - 2019-11-19 15:16:45.631; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatThread; [Consumer clientId=consumer-1, groupId=test-consumer-group] Heartbeat thread failed due to unexpected error
java.lang.OutOfMemoryError: GC overhead limit exceeded
	at org.apache.kafka.common.network.KafkaChannel.hashCode(KafkaChannel.java:367)
	at java.util.HashMap.hash(HashMap.java:338)
	at java.util.HashMap.containsKey(HashMap.java:595)
	at java.util.HashSet.contains(HashSet.java:203)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:558)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:496)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:425)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:271)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.pollNoWakeup(ConsumerNetworkClient.java:310)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatThread.run(AbstractCoordinator.java:1020)
ERROR - 2019-11-19 15:16:45.639; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: null
java.lang.RuntimeException: java.lang.OutOfMemoryError: GC overhead limit exceeded
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatThread.run(AbstractCoordinator.java:1087)
Caused by: java.lang.OutOfMemoryError: GC overhead limit exceeded
	at org.apache.kafka.common.network.KafkaChannel.hashCode(KafkaChannel.java:367)
	at java.util.HashMap.hash(HashMap.java:338)
	at java.util.HashMap.containsKey(HashMap.java:595)
	at java.util.HashSet.contains(HashSet.java:203)
	at org.apache.kafka.common.network.Selector.attemptRead(Selector.java:558)
	at org.apache.kafka.common.network.Selector.pollSelectionKeys(Selector.java:496)
	at org.apache.kafka.common.network.Selector.poll(Selector.java:425)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:510)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:271)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.pollNoWakeup(ConsumerNetworkClient.java:310)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatThread.run(AbstractCoordinator.java:1020)
WARN  - 2019-11-19 15:16:54.932; org.springframework.context.support.AbstractApplicationContext; Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'articleRepository': Cannot resolve reference to bean 'elasticsearchTemplate' while setting bean property 'elasticsearchOperations'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'elasticsearchTemplate' defined in class path resource [es.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.elasticsearch.core.ElasticsearchTemplate]: Constructor threw exception; nested exception is java.lang.OutOfMemoryError: GC overhead limit exceeded
INFO  - 2019-11-19 15:16:54.933; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:18:01.021; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:18:01.317; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:18:01.632; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:18:02.888; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:18:02.967; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:18:02.968; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:18:02.977; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:18:03.188; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:18:03.191; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:18:03.194; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:18:03.194; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:18:03.195; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:18:03.206; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 96
INFO  - 2019-11-19 15:18:03.208; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:18:03.208; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:18:04.675; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:18:06.219; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5195 ms
INFO  - 2019-11-19 15:18:06.363; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 15:18:06.735; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 15:18:07.071; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 708 ms
INFO  - 2019-11-19 15:18:27.861; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 15:18:27.868; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 15:18:27.870; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 15:18:30.447; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 15:18:30.625; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 15:18:30.999; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 15:18:31.893; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 15:18:31.957; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 15:18:31.957; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 15:18:31.963; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 15:18:32.181; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 15:18:32.183; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 15:18:32.186; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 15:18:32.186; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 15:18:32.186; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 15:18:32.201; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 98
INFO  - 2019-11-19 15:18:32.203; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 15:18:32.203; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 15:18:33.490; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 15:18:34.517; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4068 ms
INFO  - 2019-11-19 15:18:34.609; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 15:18:35.012; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 15:18:35.323; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 714 ms
INFO  - 2019-11-19 15:40:50.453; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-19 15:40:59.857; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 16:09:21.217; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-19 16:09:22.120; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 16:17:52.362; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 16:17:52.370; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 16:17:52.372; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 16:17:55.371; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 16:17:55.573; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 16:17:55.948; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 16:17:57.290; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 16:17:57.411; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 16:17:57.411; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 16:17:57.424; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 16:17:57.628; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 16:17:57.633; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 16:17:57.639; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 16:17:57.640; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 16:17:57.641; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 16:17:57.660; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 100
INFO  - 2019-11-19 16:17:57.662; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 16:17:57.663; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 16:17:59.285; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 16:18:00.436; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5063 ms
INFO  - 2019-11-19 16:18:00.519; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 16:18:00.876; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 16:18:01.201; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 681 ms
INFO  - 2019-11-19 16:19:06.787; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 16:19:06.792; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 16:19:06.793; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 16:19:10.158; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 16:19:10.301; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 16:19:10.617; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 16:19:11.451; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 16:19:11.524; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 16:19:11.524; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 16:19:11.531; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 16:19:11.676; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 16:19:11.680; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 16:19:11.683; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 16:19:11.683; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 16:19:11.683; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 16:19:11.693; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 102
INFO  - 2019-11-19 16:19:11.694; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 16:19:11.695; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 16:19:13.041; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 16:19:14.249; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4089 ms
INFO  - 2019-11-19 16:19:14.321; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 16:19:14.650; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 16:19:14.928; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 606 ms
INFO  - 2019-11-19 16:19:21.519; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 16:19:21.525; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 16:19:21.527; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 16:19:26.272; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 16:19:26.447; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 16:19:26.744; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 16:19:27.595; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 16:19:27.652; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 16:19:27.652; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 16:19:27.658; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 16:19:27.798; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 16:19:27.801; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 16:19:27.805; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 16:19:27.807; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 16:19:27.807; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 16:19:27.818; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 104
INFO  - 2019-11-19 16:19:27.820; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 16:19:27.820; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 16:19:29.187; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 16:19:30.559; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4284 ms
INFO  - 2019-11-19 16:19:30.630; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 16:19:30.982; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 16:19:31.285; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 654 ms
INFO  - 2019-11-19 16:19:58.211; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 16:19:58.220; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 16:19:58.222; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-19 16:20:04.889; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-19 16:20:05.091; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-19 16:20:05.379; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-19 16:20:06.595; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-19 16:20:06.679; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-19 16:20:06.679; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-19 16:20:06.685; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-19 16:20:06.870; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-19 16:20:06.873; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-19 16:20:06.877; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-19 16:20:06.877; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-19 16:20:06.878; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-19 16:20:06.887; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 106
INFO  - 2019-11-19 16:20:06.890; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-19 16:20:06.890; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-19 16:20:08.541; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-19 16:20:10.576; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5685 ms
INFO  - 2019-11-19 16:20:10.652; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-19 16:20:11.038; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-19 16:20:11.590; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 938 ms
INFO  - 2019-11-19 16:20:21.292; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-19 16:20:21.297; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-19 16:20:21.298; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:20:07.585; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:20:07.995; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:20:08.407; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:20:09.758; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:20:10.049; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:20:10.049; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:20:10.055; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:20:12.149; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:20:13.567; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:20:13.681; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6053 ms
INFO  - 2019-11-20 08:20:13.874; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:20:13.990; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:20:13.995; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:20:13.996; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:20:13.996; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:20:14.550; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:20:15.092; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1217 ms
INFO  - 2019-11-20 08:20:18.419; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 108
INFO  - 2019-11-20 08:20:18.421; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:20:18.422; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:20:37.226; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-20 08:22:58.091; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:22:58.227; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:22:58.228; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:22:59.274; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-20 08:23:01.157; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:23:01.448; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:23:01.809; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:23:03.074; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:23:03.166; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:23:03.166; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:23:03.172; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:23:03.476; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:23:03.481; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:23:03.488; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:23:03.489; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:23:03.489; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:23:03.506; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 110
INFO  - 2019-11-20 08:23:03.508; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:23:03.508; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:23:05.167; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:23:06.629; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5470 ms
INFO  - 2019-11-20 08:23:06.705; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:23:07.157; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:23:07.698; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 993 ms
INFO  - 2019-11-20 08:27:20.099; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-20 08:29:12.038; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:29:12.047; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:29:12.048; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:29:13.983; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-20 08:29:16.105; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:29:16.357; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:29:16.739; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:29:17.905; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:29:18.040; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:29:18.041; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:29:18.047; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:29:18.274; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:29:18.280; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:29:18.285; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:29:18.285; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:29:18.285; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:29:18.356; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 112
INFO  - 2019-11-20 08:29:18.361; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:29:18.361; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:29:20.059; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:29:21.811; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5703 ms
INFO  - 2019-11-20 08:29:21.944; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:29:23.019; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:29:23.461; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1516 ms
INFO  - 2019-11-20 08:29:40.875; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:29:40.891; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:29:40.895; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:29:44.194; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:29:44.451; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:29:44.827; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:29:46.154; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:29:46.233; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:29:46.233; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:29:46.238; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:29:46.447; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:29:46.449; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:29:46.453; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:29:46.453; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:29:46.454; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:29:46.470; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 114
INFO  - 2019-11-20 08:29:46.472; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:29:46.472; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:29:48.084; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:29:49.279; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5082 ms
INFO  - 2019-11-20 08:29:49.356; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:29:49.734; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:29:50.100; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 744 ms
INFO  - 2019-11-20 08:29:52.577; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:29:52.582; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:29:52.583; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:29:56.099; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:29:56.264; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:29:56.602; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:29:57.735; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:29:57.803; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:29:57.805; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:29:57.816; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:29:57.991; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:29:57.997; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:29:58.003; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:29:58.003; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:29:58.003; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:29:58.020; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 116
INFO  - 2019-11-20 08:29:58.022; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:29:58.022; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:29:59.671; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:30:01.483; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5382 ms
INFO  - 2019-11-20 08:30:01.619; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:30:02.587; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:30:03.113; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1494 ms
INFO  - 2019-11-20 08:30:21.352; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:30:21.359; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:30:21.361; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:30:25.630; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:30:26.282; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:30:26.672; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:30:27.877; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:30:27.999; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:30:27.999; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:30:28.010; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:30:28.287; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:30:28.290; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:30:28.294; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:30:28.295; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:30:28.295; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:30:28.310; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 118
INFO  - 2019-11-20 08:30:28.312; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:30:28.313; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:30:30.202; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:30:31.492; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5857 ms
INFO  - 2019-11-20 08:30:31.607; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:30:38.003; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:30:38.373; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 6766 ms
INFO  - 2019-11-20 08:30:53.319; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:30:53.333; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:30:53.335; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:31:04.291; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:31:04.503; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:31:05.479; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:31:06.908; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:31:06.994; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:31:06.995; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:31:07.002; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:31:07.223; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:31:07.226; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:31:07.230; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:31:07.230; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:31:07.231; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:31:07.252; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 120
INFO  - 2019-11-20 08:31:07.255; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:31:07.255; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:31:09.951; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:31:12.423; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 8130 ms
INFO  - 2019-11-20 08:31:13.339; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:31:13.901; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:31:26.043; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 12703 ms
INFO  - 2019-11-20 08:31:29.598; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:31:29.604; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:31:29.605; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:35:19.147; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:35:19.563; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:35:20.022; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:35:21.936; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:35:22.106; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:35:22.107; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:35:22.115; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:35:22.412; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:35:22.421; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:35:22.431; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:35:22.432; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:35:22.432; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:35:22.478; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 122
INFO  - 2019-11-20 08:35:22.479; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:35:22.480; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:35:24.267; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:35:26.182; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7030 ms
INFO  - 2019-11-20 08:35:26.315; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:35:26.907; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:35:27.355; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1040 ms
INFO  - 2019-11-20 08:35:35.216; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-20 08:36:30.326; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:36:30.336; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:36:30.338; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:36:32.011; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-20 08:36:33.558; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:36:34.071; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:36:34.461; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:36:35.606; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:36:35.732; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:36:35.732; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:36:35.749; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:36:35.972; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:36:35.975; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:36:35.979; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:36:35.980; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:36:35.980; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:36:36.013; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 124
INFO  - 2019-11-20 08:36:36.017; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:36:36.018; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:36:37.726; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:36:39.023; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5462 ms
INFO  - 2019-11-20 08:36:39.145; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:36:39.627; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:36:39.982; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 837 ms
INFO  - 2019-11-20 08:36:48.580; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-20 08:40:41.557; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:40:41.564; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:40:41.566; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:40:43.380; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-20 08:40:44.609; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:40:44.770; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:40:45.066; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:40:45.956; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:40:46.015; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:40:46.016; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:40:46.021; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:40:46.215; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:40:46.218; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:40:46.221; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:40:46.221; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:40:46.221; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:40:46.237; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 126
INFO  - 2019-11-20 08:40:46.238; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:40:46.239; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:40:47.759; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:40:48.703; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4092 ms
INFO  - 2019-11-20 08:40:48.771; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:40:49.103; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:40:49.371; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 600 ms
INFO  - 2019-11-20 08:41:28.083; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:41:28.091; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:41:28.092; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:41:31.069; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:41:31.213; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:41:31.510; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:41:32.331; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:41:32.406; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:41:32.406; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:41:32.412; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:41:32.606; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:41:32.608; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:41:32.612; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:41:32.612; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:41:32.612; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:41:32.670; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 128
INFO  - 2019-11-20 08:41:32.672; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:41:32.672; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:41:34.043; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:41:35.270; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4198 ms
INFO  - 2019-11-20 08:41:35.354; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:41:35.784; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:41:36.128; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 774 ms
INFO  - 2019-11-20 08:41:52.921; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:41:52.926; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:41:52.928; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:41:56.967; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:41:57.157; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:41:57.527; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:41:58.415; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:41:58.515; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:41:58.515; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:41:58.522; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:41:58.718; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:41:58.720; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:41:58.723; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:41:58.723; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:41:58.723; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:41:58.733; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 130
INFO  - 2019-11-20 08:41:58.734; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:41:58.734; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:42:00.224; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:42:01.417; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4447 ms
INFO  - 2019-11-20 08:42:01.501; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:42:01.837; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:42:02.132; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 631 ms
INFO  - 2019-11-20 08:42:15.284; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:42:15.292; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:42:15.294; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:42:20.413; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:42:20.642; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:42:20.960; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:42:22.092; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:42:22.437; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:42:22.437; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:42:22.444; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:42:22.584; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:42:22.586; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:42:22.590; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:42:22.590; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:42:22.590; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:42:22.603; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 132
INFO  - 2019-11-20 08:42:22.605; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:42:22.605; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:42:24.582; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:42:28.407; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 7991 ms
INFO  - 2019-11-20 08:42:28.487; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:42:29.046; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:42:40.091; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 11603 ms
INFO  - 2019-11-20 08:42:59.810; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:43:00.121; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:43:00.443; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:43:01.686; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:43:01.795; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:43:01.796; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:43:01.803; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:43:01.999; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:43:02.002; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:43:02.006; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:43:02.006; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:43:02.006; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:43:02.029; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 134
INFO  - 2019-11-20 08:43:02.031; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:43:02.031; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:43:03.570; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:43:04.803; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4989 ms
INFO  - 2019-11-20 08:43:04.896; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:43:05.268; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:43:05.622; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 725 ms
INFO  - 2019-11-20 08:43:11.283; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-20 08:43:31.235; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:43:31.242; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:43:31.243; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:43:33.054; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-20 08:43:34.536; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:43:34.776; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:43:35.153; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:43:36.211; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:43:36.290; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:43:36.291; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:43:36.299; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:43:36.499; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:43:36.502; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:43:36.506; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:43:36.506; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:43:36.507; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:43:36.559; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 136
INFO  - 2019-11-20 08:43:36.561; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:43:36.561; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:43:38.106; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:43:39.187; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4648 ms
INFO  - 2019-11-20 08:43:39.264; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:43:39.664; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:43:39.971; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 707 ms
INFO  - 2019-11-20 08:43:49.274; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-20 08:45:10.443; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 08:45:10.450; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 08:45:10.451; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 08:45:11.621; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-20 08:45:12.870; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 08:45:13.107; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 08:45:13.535; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 08:45:14.498; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 08:45:14.606; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 08:45:14.606; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 08:45:14.621; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 08:45:15.069; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 08:45:15.071; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 08:45:15.073; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 08:45:15.074; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 08:45:15.074; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 08:45:15.086; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 138
INFO  - 2019-11-20 08:45:15.088; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 08:45:15.088; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 08:45:16.479; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 08:45:17.417; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4544 ms
INFO  - 2019-11-20 08:45:17.507; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 08:45:17.903; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 08:45:18.167; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 660 ms
INFO  - 2019-11-20 08:45:26.849; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-20 09:55:52.942; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2019-11-20 09:55:52.967; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@59e5ddf, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@536aaa8d, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@e320068, org.springframework.test.context.support.DirtiesContextTestExecutionListener@1f57539, org.springframework.test.context.transaction.TransactionalTestExecutionListener@76f2b07d, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@704a52ec]
INFO  - 2019-11-20 09:55:53.365; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 09:55:54.027; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 09:55:55.164; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 09:55:55.260; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 09:55:55.261; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 09:55:55.268; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 09:55:55.454; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 09:55:55.456; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 09:55:55.459; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 09:55:55.459; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 09:55:55.460; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 09:55:57.869; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Attempt to heartbeat failed since group is rebalancing
INFO  - 2019-11-20 09:55:57.873; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions [articles-0]
INFO  - 2019-11-20 09:55:57.873; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: [articles-0]
INFO  - 2019-11-20 09:55:57.873; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 09:55:57.926; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 139
INFO  - 2019-11-20 09:55:57.927; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2019-11-20 09:55:57.928; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2019-11-20 09:56:23.901; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 09:56:24.212; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 09:56:24.597; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 09:56:25.979; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 09:56:26.084; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 09:56:26.084; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 09:56:26.096; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 09:56:26.300; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 09:56:26.304; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 09:56:26.309; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 09:56:26.310; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 09:56:26.311; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 09:56:26.330; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 141
INFO  - 2019-11-20 09:56:26.333; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 09:56:26.333; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 09:56:28.127; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 09:56:29.520; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5615 ms
INFO  - 2019-11-20 09:56:29.630; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 09:56:30.044; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 09:56:30.437; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 806 ms
INFO  - 2019-11-20 09:56:30.907; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-20 10:03:04.612; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-20 10:03:04.629; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-20 10:03:04.631; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-20 10:03:05.851; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
INFO  - 2019-11-20 10:03:07.496; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 10:03:07.691; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 10:03:08.014; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 10:03:08.999; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 10:03:09.080; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 10:03:09.081; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 10:03:09.089; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 10:03:09.303; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 10:03:09.305; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 10:03:09.308; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 10:03:09.308; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 10:03:09.309; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 10:03:09.319; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 143
INFO  - 2019-11-20 10:03:09.321; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 10:03:09.321; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 10:03:10.696; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 10:03:11.903; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 4405 ms
INFO  - 2019-11-20 10:03:11.991; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 10:03:12.356; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 10:03:12.622; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 631 ms
INFO  - 2019-11-20 10:33:21.682; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-20 10:33:26.795; org.apache.kafka.clients.FetchSessionHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 0: org.apache.kafka.common.errors.DisconnectException.
INFO  - 2019-11-20 10:33:26.883; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 10:33:58.540; org.apache.kafka.clients.FetchSessionHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Error sending fetch request (sessionId=INVALID, epoch=INITIAL) to node 0: org.apache.kafka.common.errors.DisconnectException.
INFO  - 2019-11-20 10:46:21.967; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-20 10:46:33.336; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 10:51:09.818; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-20 10:51:10.208; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-20 10:51:10.573; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-20 10:51:12.072; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-20 10:51:12.167; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-20 10:51:12.167; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-20 10:51:12.178; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-20 10:51:12.413; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-20 10:51:12.417; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 10:51:12.424; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-20 10:51:12.424; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-20 10:51:12.424; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-20 10:51:12.466; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 145
INFO  - 2019-11-20 10:51:12.468; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions [articles-0]
INFO  - 2019-11-20 10:51:12.468; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: [articles-0]
INFO  - 2019-11-20 10:51:14.223; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
INFO  - 2019-11-20 10:51:15.848; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 6025 ms
INFO  - 2019-11-20 10:51:15.942; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-20 10:51:16.337; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-20 10:51:16.645; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 703 ms
INFO  - 2019-11-20 10:51:17.112; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
ERROR - 2019-11-20 11:07:52.019; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = articles, partition = 0, offset = 2058, CreateTime = 1574219271370, serialized key size = -1, serialized value size = 9424, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"categoryId":2,"channelId":1,"content":"原标题：00后社交：兴趣，荷尔蒙，与交友的秘密 对社交的渴望是写在我们基因里的代码。 作者 | Lexie 责编 | 蒋丰 今年被称为社交产品年，无数创业者前赴后继，追逐着新一代社交网络的梦想宝座。 年内50多款社交类软件的上新，只不过发展上…似乎没那么顺利。 陌陌的换脸应用ZAO出现3天便因为因此安全问题被下架，字节跳动的音乐社交软件音遇因为涉黄视频也全网下架，微博的新产品绿洲享年2天因设计涉嫌抄袭火速下架，公开向微信宣战的罗永浩的聊天宝和快播创始人王欣的马桶MT也都半途折戟。 而微信目前月活却已突破11亿大关，坐实老大地位。 对于00后来说，反观国内的社交市场被两微一抖占据，国外却是百花齐放的景象。 美国00后社交App Monkey：先聊个五毛钱的 美国00后最爱的社交软件，这款叫Monkey的视频聊天软件绝不能错过。创始人16岁高中辍学搞事情，颜值爆表，人称澳洲贾斯汀比伯Ben Pasternak👇 17年，一经发布立马涨粉5万用户，此后多次登顶App Store社交类软件的榜首，基本就没掉出过榜内Top 30。 打开Monkey，可以和系统随机匹配给你的陌生人视频聊天，刺激的是，限时15秒，到点后，要么双方续时，要么好走不送👇 创始人Ben表示，新时代的交友不再局限于身边的人，而是想要把你和来自世界各地的人连接起来，为00后们追求新鲜有趣的交友体验加足火力。 去年初，Monkey成功融资200万美元，被主要竞争对手 – 想要大力开拓美国青少年市场的Holla收购，而Ben也开始寻觅全新的项目。 两家创始人都表示视频聊天是未来交友的重要走向。 tbh：真心话大冒险 说到“Gossip Girl”，大家脑海中都会浮现贵族学校里被大家窃窃私语的绯闻韵事。 有趣的是，这款叫做tbh (to be honest)的社交软件，却铁了心把背地里讲的悄悄话搬上台面，本着公开诚实的原则，让大家公开讨论学校里的那些事。 以投票的形式匿名进行“真心话大冒险”，系统给出的问题提示大多充满正能量，比如“谁的笑容最可爱？”“谁是捣蛋鬼？”👇 许多人猜测，tbh软件的命名和公司创立时在Instagram上流行的“真心话大冒险”游戏紧密相连，许多人把“tbh”当做一种Instagram货币来使用，只要有人给你的照片点赞，你就要对他说一句真心话。 发布于2017年8月的tbh在App Store上架后迅速上位，九个星期内就获得了500万用户下载和250万日活用户的好成绩，两个月后就被Facebook火速收购。 Facebook此举不但是想要和老对手“阅后即焚”的Snapchat相抗衡，也是为了“不惜一切代价实现增长”的目标偷师如何俘获中学生用户的芳心👇 可惜的是，18年Facebook宣布由于用户使用数实在可怜，tbh到此结束。 许多人都开玩笑说，是因为加入了脸书的app在青少年眼中就瞬间不酷了… Islands：没人是一座孤岛 这款叫做Islands的app创立于16年，创始人Greg Isenberg来自加拿大，在此之前还创立了视频内容推荐平台5by，后被推荐引擎StumbleUpon收购。 卖掉5by后，Greg跟自己发誓说要休息一阵。结果在洛杉矶的一次募资会上遇到了一个23岁的肺癌患者女孩，听说了她和其他的年轻肺癌患者通过邮件分享经历，从中得到支持和鼓励的故事。 Greg大受鼓舞，想为年轻人们提供一个交友的新平台，怀着相遇让生活更加奇妙的美好心愿，创立了islands👇 以大学生为主要用户的islands以个人兴趣为主要卖点，让用户们可以创立群组搞各项活动，分享课上笔记等👇 今年6月， Greg在自己的脸书上宣布“我们要加入WeWork大家庭啦。” 就此正式宣告WeWork对Islands的收购。 WeWork将Islands纳入旗下，便是想通过增强传讯能力，让会员们能够更加方便的“传小纸条”，创造更多紧密的联系。 社交背后的担忧 不过哪里有社交，哪里就有潜在隐患。尤其是00后社交，由于未成年人对于危险和刺激的辨别能力比较弱，充满未知可能的app背后也存在着未知的风险。 隐患1：和陌生人聊天 比如Monkey背后就存在着许多让家长担忧的问题。首先便是跟陌生人聊天这一点，由于Monkey不对年龄身份做限制，没人能确保孩子到底在跟谁聊天。 许多家长甚至将这款软件叫做恋童癖的温床，虽然Monkey的创始人表示他们在采取措施识别并封杀色情内容及有关账号，但家长们仍频繁表示自己曾经在孩子用Monkey 的时候看到触目惊心的淫秽内容。 隐患2：同龄人的攀比 tbh虽然主打“正能量”，但背后也充满了青少年间的攀比竞争和同辈压力。 由于所有的投票都是匿名，所以00后用户们自然会认为，自己对于说出的话和做出的选择不必承担任何重要责任。 即使系统给出的提示多是正面的问题，像是“谁是捣蛋鬼？” “谁长的最帅？”稍不小心，就会被当成讽刺和恶作剧，伤害到别人的感情。因为网络言语攻击而酿成的悲剧，我们也真的没少见，但对于网络暴力，要找到终极的解药，还是太难了… 隐患3：数据隐私边界 最为重要的是隐私问题，Moneky不但会收集关于姓名、照片、出生年月日在内的多项用户信息，收集照片、信息、视频等全部通话记录，还会把这些信息和第三方机构分享。 App在用户隐私条约中就声明了由于互联网的公开性，本身不对用户信息的丢失、滥用、篡改负任何责任。 所以，每当我们下载一个新app的时候，对于新体验的极大渴望让我们大多数人都不会停下脚步。 认真去阅读我们的隐私到底有没有保障，再加上后“脸书”时代信息私人化带来的极大便利，个人信息被收集似乎成为了兵家常事，但仔细想想这些信息和隐私都用在了哪里，真的是细思恐极。 对社交App又爱又恨 都说00后是离不开手机的一代，不过现如今的年轻人跟社交媒体之间的关系，却更适合用又爱又恨来形容。 根据PRWeek的调查，72%的青少年觉得使用社交媒体实在太占时间，29%的人觉得因为社媒感觉被伤害了自尊心，因此大批的青少年选择彻底下线，或是开小号来真实表达自我。 但随着00后即将在2020年占据全美三分之一的人口比例，Facebook等老牌平台逐渐过时，00后社交市场未来有着无限可能，大批全新社交软件随时将会到达战场，年轻人们到底有什么诉求呢？ 需求1：志同道合 不管是Islands内不同的兴趣群组，Amino上各式各样的社区，还是Instagram上不同类别的标签，都证明了兴趣爱好主导着如今的社交趋势。 与其局限于学校、社区等基本交友环境，如今的年轻人更在乎兴趣使然，志同道合这一卖点。 社交产品如果能用兴趣爱好作为磁铁，将来自不同区域和年龄层的用户巧妙集合，用户增长便不在话下。 需求2：新鲜刺激 Instagram和Pinterest的火速流行告诉我们，仅仅视觉吸引力这一点就足够成就一个平台。 根据Sparks and Honey的报告，以00后为代表的年轻人的注意力周期仅有8秒，他们不再想要花时间阅读大量文字，相反想要在短时间内就获得视觉听觉的极大感官刺激。 对于社交也一样，不管是Monkey视频交友的流行，还是Tik Tok短视频的致命式上瘾体验，什么好玩年轻人玩什么，只要能赚足眼球，哪怕是世界另一端的陌生人，也请放马来吧。 需求3：FOMO （Fear Of Missing Out） 你有问过自己为什么会刷朋友圈刷微博到半夜吗？其实这背后都是FOMO（错失恐惧症）的驱使，而对于每天都有新鲜事的青少年花花世界来说，更是如此。 tbh当年的内部报告显示，他们用户增长的重要方法就是通过针对高中，创造一种“你的同学都在用”的感觉，让潜在用户对于自己被遗漏在外产生极大恐惧，因此必须加入游戏。不管是必备体验，还是社交等级，年轻人虽特立独行，但对于这份归属感的渴望，也货真价实。 想在社交赛道占据一隅之地，互联网公司需要靠自己的逻辑为用户编织社交之网。 美国青少年社交软件的成功或许有所启发。对于00后来说，社交的美妙就在于，探索世界的欲望与向世界展示自己的欲望，两者完全可以在一定程度上互相补足。 不管是国内还是美国，人际关系和社交需求的市场都还有着无限的可能。用细分领域和垂直社区去主打，创造更多深层且难忘的社交体验，或许是全新出路。 未来到底是老牌屹立不倒，还是后浪盖过前浪，让我们拭目以待。 -END-返回搜狐，查看更多 责任编辑：","contentType":0,"created":1574219271370,"deleted":0,"hits":0,"hot":1,"keywords":"网易","original":"网易","status":1,"title":"00后社交：兴趣，荷尔蒙，与交友的秘密","userId":155})
org.springframework.jdbc.UncategorizedSQLException: 
### Error updating database.  Cause: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1
### The error may involve com.liujian.cms.dao.ArticleMapper.insertSelective-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article      ( title,                              channel_id,                       category_id,                       user_id,                       hits,                       hot,                       status,                       deleted,                       created,                              content,                               content_type,                          keywords,                          original )       values ( ?,                              ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                              ?,                               ?,                       ?,                          ? )
### Cause: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1
; uncategorized SQLException; SQL state [HY000]; error code [1366]; Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1; nested exception is java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:89)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy40.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy41.insertSelective(Unknown Source)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:47)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:30)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1055)
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:956)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3491)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy81.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 15 more
ERROR - 2019-11-20 11:07:52.322; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = articles, partition = 0, offset = 2101, CreateTime = 1574219272167, serialized key size = -1, serialized value size = 1147, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"categoryId":2,"channelId":1,"content":"原标题：Facebook 为 WhatsApp、Instagram 等应用带来支付服务 Facebook Pay Facebook 日前启动了名为 Facebook Pay 的移动支付系统，用户可通过它在 Facebook、Messenger、Instagram 和 WhatsApp 上向向朋友汇款、购物或向筹款人进行捐赠。Facebook 表示，该服务将与他们的 Calibra 钱包和 Libra 网络分开，并且 “基于现有的金融基础设施和合作伙伴关系”。 Facebook 计划本周开始在美国地区针对 Messenger 和 Facebook 推出 Facebook Pay。“随着时间的推移，我们计划将 Facebook Pay 向更多用户和地区推广，包括在 Instagram 和 WhatsApp 中使用，” Facebook 市场和商务副总裁 Deborah Liu 解释说。 Facebook 并未透露 Facebook Pay 何时可在旗下所有应用中使用，也未透露何时会在全球推出。返回搜狐，查看更多 责任编辑：","contentType":0,"created":1574219272166,"deleted":0,"hits":0,"hot":1,"keywords":"网易","original":"网易","status":1,"title":"Facebook 为 WhatsApp、Instagram 等应用带来支付服务 Facebook Pay","userId":155})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.liujian.cms.dao.ArticleMapper.insertSelective-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article      ( title,                              channel_id,                       category_id,                       user_id,                       hits,                       hot,                       status,                       deleted,                       created,                              content,                               content_type,                          keywords,                          original )       values ( ?,                              ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                              ?,                               ?,                       ?,                          ? )
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy40.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy41.insertSelective(Unknown Source)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:47)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:30)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor195.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy81.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor194.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 15 more
ERROR - 2019-11-20 11:07:52.858; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = articles, partition = 0, offset = 2142, CreateTime = 1574219272818, serialized key size = -1, serialized value size = 19187, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"categoryId":2,"channelId":1,"content":"原标题：上天赏饭吃，她却一步一步走向毁灭 虽然今天热搜爆了一对网红分手撕X瓜，但我打算跳过这一题。 和对象和内容无关，纯属没有心情，因为刚刚刷到日本媒体关于泽尻英龙华吸毒事件的最新报道时发现，她现在这个也有涉毒嫌疑的男朋友是从2011年就开始交往的…… 泽尻2009年结婚，2013年离婚，虽说过程中早就有了分开的意向也一直在打官司，但无论如何，没彻底解除婚姻契约关系之前就发展新的亲密关系，就是“婚内出轨”就是黑历史。 来算算这位女士最近几天搞出多少事： 11月16号下午，泽尻英龙华因为涉嫌毒品取缔法，被警视厅组织犯罪对策部逮捕。 警察在她位于东京目黑区的家里搜到了两粒疑似装有MDMA（亚甲二氧甲基苯丙胺，简单来说就是摇头丸）粉末的胶囊，于是将她带到警视厅本部接受调查。 她在受讯时承认了被查出来的东西的确是自己的，按照流程，泽尻被移送到东京湾岸警署，之后又被送交监察厅。 事务所也出了相关说明👇 一开始，还有一些人对事件持保留态度，因为泽尻的尿检呈阴性，而且在承认违禁药物“是我的东西没错”时还强调自己并没有使用，这只是男朋友放在这里的…… 但我只能说想用这句补充来全盘推翻犯罪嫌疑是真的没可能，虽然我很喜欢她、她算是我的日圈初心之一，可是仔细看看新闻就没办法遗漏那句“之前有使用过”啊！ 要知道MDMA是在她放首饰的架子上找到的，女明星要打扮的话，不可能不去查看自己的梳妆装备吧？这么显然的地方还能坦然地让男朋友留下点违法的东西，要么是心大到不认识这玩意儿是啥，要么就已经习以为常到不觉得这是错。 泽尻本人又补充说明自己以前吸过，那不等于直接漏题告诉你前者是不可能的错误选项了吗？ 警察也怀疑搜出来的东西是她自己以前用剩下的，并且推测泽尻可能经常吸毒，要继续展开深入调查。 还没查多久，这位姐就改了口风，承认自己吸毒吸了起码十年了…… 大麻、MDMA、LSD（麦角酸二乙酰胺，一种特别强烈的半人工致幻剂）、可卡因……泽尻女士说她都沾过。 不过应该不止这些，据今天新出的报道，搜查相关人员都震惊于她的“涉猎”程度，违禁药物的名字说起来那是如数家珍。“这也磕过，那也磕过”，算起来大概有十种。 嗑药磕了十来年，虽然不是每天都吸，但是频次也得按周来计算，而且每种毒品的药效和用法都说得头头是道，瘾君子无疑了。 所以最初的解释完全就是撒谎，泽尻当时不仅把锅甩给男友了，还隐瞒了MDMA小药丸的来源，根本不是谁去她家时留下的，而是她几周前在活动现场上拿的。 说到这里要先插播一下这位女士2007年的黑脸事件，那是她公众名声第一次滑铁卢。了解这事儿的影响恶劣程度，再结合经纪公司的态度以及隔很久后突然与其解约的转变，会更容易掌握关于泽尻吸毒新闻的相关知识点。 那是《尘封笔记本》的公开试映会，泽尻英龙华作为女主演，明明应该情绪饱满地为影片做宣传，但她的现场表现却非常低气压，只是在起初的招呼寒暄阶段说了句“今天真是谢谢了”，就一直抱着胳膊不说话。 有记者问拍摄最难忘的场景，看过其它影视作品播映期间的主创采访就知道这是一个再常规不过的问题了，随便说一场戏再分享点当时的心情就能轻松过关，而泽尻的回答是“特にないです”，“没什么特别的”。 导演行定勋连忙挽尊，说泽尻有烤饼干送到拍摄现场，本来是想缓和气氛，但话头好不容易递回到她那里，这位女士硬邦邦地甩出了一句“别に”，意思是“没什么”。 我发微博时有提到“别兹泥”，其实就是“别に”的发音，日本媒体把这次黑脸不配合叫做“别に”事件。 这几年我看一些人提起这件事，都说不明白为什么日本人会觉得这是个大事，“真性情而已啊”？讲真，“真性情”不是什么免死金牌。 且不说日本人本来就有强烈的长幼尊卑观念，活动现场有行定勋导演，还有比泽尻资历更深、年纪更大的竹内结子，怎么都轮不到24岁的她拿腔拿调。只说这么硬茬到底尊不尊重人吧，媒体记者也是为了要出稿才问问题，来这一趟都是为了生计而奔波，一没说脏话二没侵犯你隐私，其三人家的工作严格来说还是在帮你宣传、为你服务，当众甩脸子是合适的吗？ 当时各界反馈很能说明问题： 德不是很高但名望挺高的大姐头和田秋子，直接在节目里吐槽泽尻嚣张，“她以为她是女王吗？让我遇到就要她好看！” 《医龙2》恰逢开播，记者会上，男主坂口宪二被问及“新剧有什么卖点”的时候也故意装作心情很不好的样子，说“没什么特别的”，摆明了就是拿泽尻这件事当梗。 本来《尘封笔记本》要去釜山电影节宣传，因为影响不好，制作方东宝映画也临时跟经纪公司Stardust要求把泽尻给撤了，不让她跟剧组去走红毯。 但即使是这样，Stardust也没有真的放弃泽尻。 他们让泽尻在官网上发了一篇道歉文，同时泪流满面地出来“谢罪”，说自己做错了、会为事件负全责，“身为艺人这种表现并不专业，即使作为一个普通人来说也很不成熟。” 同时公司还出面解释，说泽尻那天突然炸毛是因为太累了。 “别に”事件之后，泽尻还照原计划发了个人单曲，2008年又拍了kanebo的广告…… △2007年11月28日发行的《Destination Nowhere》，是北川景子《抹布女孩》主题曲 △2008年秋冬投放的COFFRET D'OR彩妆广告 这些也可以说明人气大崩盘之后，Stardust对她仍有支持，即使在她和高城刚高调注册结婚时也没做台面上的反对和干涉。 △2009年1月在平安神宫举行了仪式，第一次看到短眉毛配全包黑眼线还能这么好看的人 可是时间来到2009年9月30号，“别に”事件发生两年后，公司突然宣布和泽尻解约，并且说她“有重大违约之事由”。但具体是什么，Stardust并没有对外公布。 直到2012年，泽尻带着她主演的新作《狼狈》准备重磅回归时，《周刊文春》突然甩出一篇深度报道，从三年前她解约的文件入手进行调查，发现所谓的“重大违约事由”就是泽尻吸毒。 据报道显示，泽尻于2009年9月10号接受了Stardust安排的药物反应检查，结果呈大麻阳性。检查是全公司的艺人都做了，泽尻本人知情且同意，她也承认自己吸大麻，还表明了没办法戒断的意思，所以公司最终决定要跟她解约。 没办法，在这之前一个月里，押尾学和酒井法子先后爆发吸毒丑闻，日本演艺界人心动荡，你这有实锤了还不悔改，不解约还留着当炸弹吗？ △2009年8月2号，押尾学和一名银座女公关一起吸毒，女方突然死亡，押尾学在她出事后3小时才去报警，第二天就因违反毒品取缔法被起诉 △酒井法子，不说了，之前有写过👉《谁会给她钱啊》 报道发出去后，《周刊文春》还采访到了泽尻的前夫高城刚，他肯定了这个说法，表示2009年9月药物反应检查结果出来后，自己被叫到了Stardust公司，从理事F某和经纪人K某那里知道了这件事，解约文件没错，泽尻是因为涉毒才被开除的也没错。 高城刚还说，他在当时居住的伦敦找了间治疗中心让泽尻去戒毒，泽尻很配合，看起来也重新振作了，所以两人结婚了。但是后来因为泽尻单方面提出离婚，在律师的斡旋下，她又去了西班牙的巴塞罗那，住在高城刚的公寓里。 在巴塞罗那的时候，泽尻又认识了一个自称为“大麻instructor（讲师？教员？）”的男人Sergio（セルジオ，音译应该是“赛吉欧”），并因为他重新染上了毒品。泽尻自己跟高城刚说她跟Sergio一起睡了觉，而且还用上了摇头丸。 和Sergio这段，《周刊文春》拿出了照片，虽然不是他跟泽尻一起吸食毒品或是亲昵的画面，硬要反驳也不是不行，可是看得出来泽尻就是一副玩嗨了的样子。 高城刚说他跟泽尻的同事啊朋友啊都说过“她又复吸了”，而且还说了好几次，但大家都表示看不出，“她看起来没事啊”“就这样挺好的”，压根没把他说的当真。 细心的朋友们可能发现了，高城刚提到了“单方面提出离婚”。 是的，虽然正式离婚是在2013年底，但结婚后1年零3个月，也就是2010年4月，泽尻就对外公开了“离婚意愿”，说是男方一直拖着没签字。 在肯定泽尻因为吸毒被解雇这件事的真实性之外，高城刚还针对这件事爆了个料，说这可能是Avex公司搞的鬼，因为这家唱片公司老总松浦胜人看上了泽尻，以“如果和Avex签约的话就可以从头再来”为诱饵想钓泽尻做自己的情妇。 △松浦胜人还蛮常在SNS上发和泽尻的合照的 高城刚还加码透露，松浦胜人一再强调“Avex会让你重返娱乐圈，离婚吧。因为我们是Avex，所以我们会想办法。”并且用毒品撩拨泽尻，说随时都可以准备云云。 当时高城刚还是泽尻在法律上的老公，他却对着媒体说泽尻被“软禁”在了六本木的高级公寓里，听居心叵测的人说了很多关于自己的坏话。 2012年《狼狈》还没上映、没出熟肉字幕之前，除了一部分本身就对日本娱乐圈感兴趣的日饭之外，国内没多少人还在意泽尻这个有几年不见大动静的女演员了，会翻译这些长篇大论的中文媒体少之又少。 况且《周刊文春》的小作文在日饭群体之间的被采纳度并不是那么高，毕竟有些东西说得煞有介事，但不出过硬实锤，又会带动一系列辟谣新闻联动刷屏，看得人脑仁爆炸。 总之因为各种原因，《周刊文春》在2012年就泽尻可能涉毒做出的系列报道，并没有引起大家的重视，以至于现在她被抓了自己招了，我们再感慨“美人何必作死”，却忽略了所有的大翻车之前都会有例行的“山雨欲来风满楼”。 打字的时候我挺激动的，失望的那种激动，可能大家也从字里行间里看得出来叙述的口吻和平常不太一样，夹杂了很强的个人情绪。 因为我真的非常喜欢泽尻：《一公升的眼泪》对我影响深远，直到2019年我都还会庄重地过每个3月9日。那部剧之后的两年，我又被她以“ERIKA”名义发布的单曲《Free》狠狠秒过，无论是现在看来很俗的PV还是歌声里的劲儿都刚好击中了我的审美点。 收藏了太多她的写真画报，泽尻结婚前大部分图片，我一度能做到看一眼就分清大概是在什么阶段拍的，所属特辑名字叫什么…… △2007年这本《Erika 2007》是我心中经典 △08年清川あさみ出了本《美女采集》，拍了22位日本当时正红的女演员、歌手或模特，想象力绮丽无比，泽尻这张的主题是“蜘蛛” 这些年看着她从资源停摆到现在CM（广告）不停，从只能演演BeeTV的小成本手机剧到明年终于可以出演NHK大河剧，我真觉得这位女士可能要熬出头了。 △她真不是“逆天改命”，2012年主演这部剧小众到什么程度呢？当时好不容易出了字幕档，画面糊得非常感人 △好不容易来了好资源，现在纯属给剧组添堵添麻烦 她近期接受了很多采访，都拿出了要好好雕琢演技的决心，说自己是真的喜欢演戏，也对过去的轻狂做了解释和再次抱歉。 甚至“别に”都能被泽尻本人当成梗来用在节目录制里了，和当初被她黑面相向那位记者主持也相逢一笑泯恩仇了，感觉这位女演员是真的成熟了长大了，懂得感恩和珍惜自己所拥有的一切了。 结果这种属于粉丝的向上的信念，在知道她吸毒被抓之后瞬间崩塌，不亚于追星女孩看到自家爱豆谈恋爱的那种房子塌。 特别是回顾了过去高城刚所爆料的种种，又看了最新的《周刊文春》报道，说她现在这个艺术指导男朋友A某是在2011年她婚内就交往上之后…… 因为泽尻大力扶持、积极给他介绍人脉的关系，A某在2015年创立了一个高级品牌，并在东京港区开了公司，公司登记信息“董事”一栏里赫然有Avex原副社长千叶龙平的名字。而A某也出现在了千叶龙平担任CEO的美国Mindfulness（冥想）公司高层名单里，身份是“艺术总监”。 还有一张A某和千叶龙平的合照，应该是和写有自己名字的灯笼打卡，因为A某并非名人也没被公开真实信息的缘故，有他的部分被打了码。但大家可以看到“千叶龙平”的名字下面有两个被挂在一起的灯笼，分别写了泽尻和Avex社长松浦胜人的名字。 这不又让人想起2012年高城刚的说法了吗？ 《周刊文春》丢锤佐证7年前旧闻的努力，到这里还不算完。他们还采访到了高城刚所说的那位让泽尻复吸的“大麻instructor”、西班牙人Sergio…… Sergio回忆起泽尻来非常爽快，说是2010上半年和她认识的，当时介绍人说泽尻是“日本来的、非常喜欢大麻的女孩”，Sergio本身就对日本文化很感兴趣，在酒吧碰面后，双方很快就一见钟情。 那位中间人朋友对泽尻说，“明天Sergio家里有大麻派对，你来不来？”第二天泽尻竟然真的主动出现在了Sergio家。 Sergio说泽尻喜欢把大麻和烟混着抽，把大麻叶子卷在纸里抽，抽的时候眼睛有点红，但是带着笑，对这些东西也很熟悉。两个人每周会见三到四次面，见面一定会抽大麻，Sergio还记得有一次是在高级饭店，泽尻买了很贵的香槟请大家喝，喝的时候也抽了大麻。 但他说自己和泽尻一起睡了三次觉，却从来没发生过关系，Sergio对此很讶异，“不知道是不是日本女孩子特有的害羞”。 Sergio还跟记者说，泽尻非常在意别人的目光，会变装来掩盖本来的自己，之所以会选巴塞罗那放松，可能是因为谁都不认识她。 Sergio见她时是听了很多人说“这个女孩很出名哦，是世界50美人之一哦”，但并没有确切概念，还是在上facebook去搜索她相关信息后，发现起码有三千个人都叫这个名字来冒充她，才确定了这真的是个很红的大明星。 △Sergio提供的一些泽尻当时嗨玩的照片 在泽尻吸毒事件曝光后，很多人都想到了《狼狈》，觉得那仿佛是她的自传，莉莉子的形象和现实中的泽尻重叠了。 但我从来不这么认为。 《狼狈》不止有奢靡和堕落，还有一个不可忽略的情节是莉莉子曾经又丑又胖，她经过了抽脂和整容才获得了巅峰的美貌，而最终的坠落也和整容手术的“反噬”息息相关。 极致的美本就是虚无，欲望生生不息，要么控制它成为自己的神，要么被它驯服化身享乐主义的奴隶——这是“狼狈”的真实意义。 而泽尻女士呢？ 混血儿出身，妈妈是阿尔及利亚裔法兰西人与柏柏尔族混血儿；出身富庶，爸爸曾经拥有几十匹赛马。她小时候就学骑马学跳舞学钢琴，后两样现在小康家庭凑一凑也能让孩子一直学，但“骑马”有几个普通家庭能做到？ △当初结婚仪式上，高城刚后面那位金发女士就是泽尻的妈妈 她出道不是穷，不是要补贴家用，单纯因为她喜欢安室奈美惠，觉得进了演艺圈就可以看到偶像。 混血是会出美人，长势却也不受控制，而泽尻是前者是天生的幸运儿，这点毫无疑问。在报名表上贴个大头贴就能被公司看中签约，给杂志当模特有持续曝光不说，还慢慢接了戏演了电影…… △99年杂志上的泽尻 △说她除了脸外啥都不好，可是当时人家是跟香里奈、市川由衣一起被选中的 虽然身材比例是虐了点，但是她脸小啊，演技又好，演部《Pacchigi!》能拿6个新人奖。 泽尻也不是什么性格软弱要受经纪公司摆布的人，用自己的原话说，从小就跟男孩一样淘。 她名字里的“erika”是假名，国内媒体翻译成“绘里香”，台湾粉丝之前建站写博一直把她叫“小香”，这位姐觉得翻得太小女生了，不行，于是2007年隆重宣布要叫自己“英龙华”，因为英气勃勃很酷，并且希望整个华语区都这么能一致用她亲自指定的这个中文名。 黑脸事件之后痛哭道歉算是稍微赚了一点好感，隔几年又能在节目上自打脸，说当时并没有真的觉得自己错了，是公司说要雪藏自己，才被迫公开道歉，声泪俱下全靠演技。 这样的人，这样的性格，哪来《狼狈》里莉莉子那极度自卑后突然膨胀的扭曲和被裹挟啊？泽尻分明就是“恃靓行凶”。 当然大家也可以反驳我，毕竟我这一番感想已经是失望透顶后的抒发，可能忽略了泽尻为演艺路所付出的心血、在表演上所下的苦功了。 看人应该要多面的看，辩证地看，她是个好演员，是天生的巨星苗子，这点毋庸置疑。 只是那又如何呢？ 说来很搞笑的是，泽尻承认自己吸毒十年以上之后，中日网友反应大同，说她这么折腾还这么美，真是老天爷赏饭吃，人生太不公平。 是啊，池内亚也和萤火永远在我心中珍藏，以后再看到泽尻的照片我可能还是会感叹她真好看。 但再也没有然后了。 如果说当年的黑面、闪婚是态度出了问题，她作为一个演员只要业务能力够强又找准机会，总能够东山再起。那现在她有了吸毒前科，深挖一下还是多年老毒物，牵涉进了一大堆钱权色欲勾结的糟心丑闻中，观众还要怎么宽恕？资本就算有心，又怎么强捧得出这么一个负面艺人？ 泽尻33岁了，走到这一步，已经回不到当初。 最后再放一些我个人很喜欢的她的图吧，美人如斯，只叹人生不能总只如初见。 原创不易，转载本文请务必注明作者以及微信号（cj10141234）。返回搜狐，查看更多 责任编辑：","contentType":0,"created":1574219272818,"deleted":0,"hits":0,"hot":1,"keywords":"网易","original":"网易","status":1,"title":"上天赏饭吃，她却一步一步走向毁灭","userId":155})
org.springframework.jdbc.UncategorizedSQLException: 
### Error updating database.  Cause: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 \xE4...' for column 'content' at row 1
### The error may involve com.liujian.cms.dao.ArticleMapper.insertSelective-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article      ( title,                              channel_id,                       category_id,                       user_id,                       hits,                       hot,                       status,                       deleted,                       created,                              content,                               content_type,                          keywords,                          original )       values ( ?,                              ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                              ?,                               ?,                       ?,                          ? )
### Cause: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 \xE4...' for column 'content' at row 1
; uncategorized SQLException; SQL state [HY000]; error code [1366]; Incorrect string value: '\xF0\x9F\x91\x87 \xE4...' for column 'content' at row 1; nested exception is java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 \xE4...' for column 'content' at row 1
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:89)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy40.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy41.insertSelective(Unknown Source)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:47)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:30)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 \xE4...' for column 'content' at row 1
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1055)
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:956)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3491)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor195.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy81.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor194.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 15 more
ERROR - 2019-11-20 11:07:57.386; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = articles, partition = 0, offset = 2424, CreateTime = 1574219277306, serialized key size = -1, serialized value size = 13765, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"categoryId":2,"channelId":1,"content":"原标题：早报 | 央行再“放水”1200亿元；最高法：微信是网络诈骗中使用最频繁的工具；港交所研究收购西班牙交易所 2018年，微信超过QQ成为网络诈骗犯罪中使用最为频繁的犯罪工具。 央行再“放水”1200亿元 LPR利率大概率下调 央行网站公告称，11月19日，人民银行在开展中央国库现金管理商业银行定期存款操作500亿元的基础上，以利率招标方式开展了1200亿元7天逆回购操作，中标利率为2.50%，与上一次持平。19日无逆回购到期，因此净投放1200亿元。11月20日将公布新的LPR报价利率，有专家表示，央行在此之前下调MLF利率和逆回购利率，可以充分引导LPR利率下行，推动降低实体企业融资成本。 中国最高法：微信是网络诈骗中使用最频繁的工具 中国最高人民法院20日召开新闻发布会，最高人民法院信息中心副主任孙福辉表示，2018年，微信超过QQ成为网络诈骗犯罪中使用最为频繁的犯罪工具，超半数网络诈骗案件中均有涉及应用微信实施诈骗的犯罪情节。 孙福辉介绍，据统计，被告人在实施网络诈骗案件时，冒充他人身份实施诈骗的案件占比达31.52%，以招聘为诱饵实施诈骗的案件占比在2018年大幅上升；冒充类型的网络诈骗案件中被告人多冒充女性或熟人；近20%的网络诈骗案件是在获取公民个人信息后进行的诈骗。 香港交易所研究收购西班牙交易所集团 西班牙报纸《五日报》援引金融行业人士的消息称，香港证券交易所的拥有者香港交易及结算所有限公司正在考虑竞标西班牙交易所集团。对此，港交所有关人士回复：“我们不评论并购传闻”。 滴滴顺风车：将在哈尔滨、太原、常州3个城市上线试运营 滴滴顺风车在滴滴出行app内更新试运营公告，宣布11月20日，顺风车将在哈尔滨、太原、常州3个城市上线试运营。同时，滴滴在公告还说明，因技术调试原定第一批试运营的北京和石家庄，将延缓至12月。 阿里巴巴提早截单：国际认购超额3-4倍 阿里巴巴20日决定提早截止机构认购。据悉，阿里巴巴机构认购订单超额倍数为3-4倍。一些机构投资者表示，和之前5%左右的折扣有很大区别，按照当前仅有2%折扣来说，实际上对于机构来说没有预期的获利空间，也就没有必要从香港资本市场再认购，美股一样可以买。 今年已诞生171只翻倍股 Wind数据显示，截至11月19日，A股市场今年以来已诞生171只涨幅在100%以上的翻倍股。在这些翻倍股的股东名单中，频频出现兴全基金、交银施罗德基金、广发基金等旗下基金产品的身影。借助牛股，目前市场上也已经有“翻倍基”的出现。对于后市，基金机构多认为，将持续结构性行情。德邦基金表示，然维持中长期看好A股的观点，配置依然以消费和科技的龙头公司为主。 再晒家底，第四次全国经济普查结果今日出炉 最新的中国经济家底清单将于今天揭晓。据国务院新闻办公室消息，国新办将于11月20日10时举行新闻发布会，介绍第四次全国经济普查结果有关情况。 哔哩哔哩Q3总营收达18.6亿元人民币，同比增长72% 本季度内，哔哩哔哩总营收达18.6亿元人民币，同比增长72%，大幅超出市场预期。B站第三季度调整后的非美国会计通用准则（Non-GAAP）的净亏损为3.4亿元人民币，去年同期净亏损为人民币2.461亿元。B站月均活跃用户达1.28亿，同比增长38%；移动端月均活跃用户首度破亿，同比增长43%达1.14亿。B站月均付费用户数同比增长124%，达到795万。 大连市农业农村局拒谈獐子岛专家组名单：“我什么都不知道” 大连市农业农村局办公室相关负责人表示，“我们只负责组织专家，专家结论不上报给我们，直接上报给大连市政府，市政府已经专门成立了领导小组。”当询问是否能提供獐子岛专家调查组名单时，该负责人直接予以拒绝称，“不方便。” 中国电信联合三星发布5G折叠屏手机：12月面世 价格未公布 随着5G进入商用阶段，结合了柔性屏科技的5G折叠屏手机成为市场热点。11月19日，中国电信和三星在武汉联合发布5G折叠屏手机，将于12月份面世，但大众最为关注的价格并未公布。 瑞银：A股家电板块将跑赢大市 瑞银19日发布最新报告表示，A股家电板块前景向好，将跑赢大市。报告指出，消费者从以往过于注重比较价格，到现在关注更多家电的功能性，生产商过去几年通过不同定位的品牌，抓住各个层面的消费力。领先的家电产商近年积极开发智能家居，用户将来可以通过物联网软件，轻易把衣食住行各个生活环节连在一起，而5G技术更利于不同商家共同建立整个生态。瑞银认为，A股家电板块的市场估值并没有反映以上利好因素。 滴滴成立传媒公司 天眼查数据显示，滴滴出行的运营主体北京小桔科技有限公司新增对外投资信息，出资1000万人民币，成立北京粒粒橙传媒有限公司。北京粒粒橙传媒有限公司法定代表人为滴滴市场部负责人王嘉杰，经营范围包括电视剧制作；音像制品制作；电子出版物制作、电影发行等，由北京小桔科技有限公司全资控股。 10家企业分拆旗下公司上市 未来分拆上市案例将增多 据不完全统计，截至11月19日，有10家公司成功分拆子公司上市，分别登陆港股或A股市场。虽然预计未来境内分拆上市案例会增多，但是整体来说符合分拆上市要求的企业数量占整体A股上市公司的数量较少。据业内人士统计，目前A股上市公司中能同时满足这些条件的数量有近100家，以大型国有企业和多元化经营的大型民企为主。 拍拍贷发布2019Q3财报，宣布升级为信也科技 头部金融科技平台拍拍贷发布了其2019年第三季度未经审计的财务报告，同时对外宣布正式升级为“信也科技集团”。拍拍贷财务数据表现依然稳健，2019年第三季度总营收达15.124亿元，同比增长35.0%，净利润5.985亿元。 银联严查信用卡违规代还行为 中国银联业务管理委员会近日发布的文件显示，中国银联将开始在未来两周内严查信用卡违规代还行为。这份名为《关于开展收单机构信用卡违规代还专项规范工作的通知》要求，从11月18日到11月29日为期两周内，收单机构应从外包服务机构合作、商户管理、交易监控等各环节全面排查是否存在信用卡违规代还业务，一旦发现、立即关停。有专家表示，此次，银联主要针对的是中国第三方支付机构及其从外包服务机构中存在的违规套现行为，即市场上流行的“套现贷”。 WeWork董事长在电邮中证实裁员计划，最早本周开始 据外媒报道，WeWork董事长马塞洛·克劳雷在周一发给员工的备忘录中证实，本周将进行裁员。但备忘录没有说明预计裁员多少人，只称该公司将于周五召开全体会议，讨论公司即将发生的变化。美国当地媒体此前报道称，办公空间共享初创企业WeWork正准备裁员至少4000人，以求实现财政稳定，这个裁员计划最早可能在本周宣布。 2019胡润财富报告新出炉：中国大陆中产家庭3320万户 19日，胡润研究院发布了《2019胡润财富报告》。报告称，截至2018年8月，中国大陆中产家庭数量已达3320万户，其中新中产1000万户以上，北京、广东和上海这三个省市的中产家庭数量共占中国大陆的50%。按区域来看，华东地区的中产家庭规模最大，占全国四成以上，达1489万户。 财政部：前十月全国一般公共预算收入167704亿元 财政部数据显示，1-10月累计，全国一般公共预算收入167704亿元，同比增长3.8%。其中，中央一般公共预算收入80662亿元，同比增长4.4%；地方一般公共预算本级收入87042亿元，同比增长3.3%。全国一般公共预算收入中的税收收入141514亿元，同比增长0.4%，累计增幅比1-9月提高0.8个百分点。 外交部回应美国宣布推迟执行华为禁令：只要求对中企平等对待 此前，美国商务部发布公告，宣布发布90天延期许可，允许美国企业继续与华为进行业务往来，有记者据此提问。耿爽表示，华为公司有关负责人已经对外公开作出回应。中方此前也多次表明过我们的立场，我们敦促美方停止泛化国家安全概念，滥用出口管制，对他国特定企业采取歧视性不公平做法，停止将经贸问题政治化。我们不要求外国政府对中国企业有任何特殊对待，我们只要求外国政府对中国企业包括华为平等对待。 中国外汇局：10月外汇市场供求基本平衡 外汇局：2019年10月，银行结汇9756亿元人民币，售汇10067亿元人民币，结售汇逆差311亿元人民币；按美元计值，银行结汇1380亿美元，售汇1424亿美元，结售汇逆差44亿美元。国家外汇管理局新闻发言人、总经济师王春英表示，10月外汇市场供求基本平衡，跨境资金流动保持稳定。外汇市场预期更趋平稳，主要渠道跨境资金流动稳中向好。一方面，主要流入渠道外汇供给稳中有增。另一方面，主要流出渠道外汇需求保持平稳。 央行部署货币信贷工作，易纲强调逆周期调节 央行网站19日消息，为深入贯彻落实党中央决策部署和国务院工作要求，2019年11月19日，人民银行行长、国务院金融稳定发展委员会办公室主任易纲主持召开金融机构货币信贷形势分析座谈会，研究当前货币信贷形势，部署下一步货币信贷工作。易纲强调，要继续强化逆周期调节，增强信贷对实体经济的支持力度，保持广义货币M2和社会融资规模增速与国内生产总值名义增速基本匹配，促进经济运行在合理区间。 前10月央行缩表1.3万亿 央行最新公布的货币当局资产负债表显示，截至10月末央行总资产为35.9万亿，相比9月末下降2326.2亿，呈现缩表的态势。对比去年年末来看，央行资产负债表收缩1.3万亿。央行回应中国央行缩表并不意味着紧缩。分析认为，后续央行价格型工具受通胀牵制，稳健略宽松的货币政策将主要通过扩信用发力，预计央行扩表在即，未来要关注PSL等扩表工具。 沙特阿美取消IPO国际路演 有媒体报道，沙特放弃了在本国及海湾邻国以外地区正式推介其国有石油公司沙特阿美股票的计划，这是此次首次公开发行雄心缩水的最新迹象。据知情人士透露，在美国和亚洲路演被取消一天后，银行家们周一获悉，与欧洲投资者的正式会议也不会举行。这一决定是这一王国遭遇的最新挫折。 岚煜生物完成近亿元C轮融资 南京岚煜生物科技有限公司宣布完成近亿元C轮资本融资，此轮融资由经纬中国领投，邦盛资本跟投。本轮融资将用于产品销售渠道拓展以及运营服务提升、新技术产品的创新研发、后期产品线的进一步拓宽等工作，提升客户服务能力。岚煜生物成立于2016年，是一家聚焦POCT技术创新与改进的研发型企业。 洪九果品完成C轮融资 股权投资机构CMC资本（CMC Capital）宣布完成对水果供应链企业“洪九果品”5亿元C轮融资的领投。至此，CMC资本通过旗下美元和人民币基金在消费领域的投资布局，完善了包含美菜、叮咚买菜、洪九果品在内的生鲜投资版图。洪九果品是一家主营水果供应链服务的企业，上游直接对接国内外优质产区果园，下游对接终端零售渠道，建立了覆盖全产业链的端到端模式。 易捷行云EasyStack获中国系统数亿元融资 中国电子系统技术有限公司（中国系统）宣布完成对易捷行云EasyStack的数亿元战略投资。本轮融资后，双方将共同构建基于PK体系的企业级云基础架构PKC，进一步完善一体化数字底座，推动我国现代数字城市建设快速发展。易捷行云EasyStack成立于2014年2月，是一家企业私有云产品服务商。 VPhoto完成B轮1亿元融资 即时影像共享服务平台VPhoto宣布完成B轮1亿元人民币融资，本轮融资由达晨财智、广发信德联合领投，繸子资产跟投。此次融资系VPhoto成立4年来获得的第7笔融资，总获融资金额近2亿元。VPhoto是即时影像共享服务平台，目前的主要业务是To B企业用户影像服务。 话题讨论：中国最高人民法院20日召开新闻发布会，最高人民法院信息中心副主任孙福辉表示，2018年，微信超过QQ成为网络诈骗犯罪中使用最为频繁的犯罪工具，超半数网络诈骗案件中均有涉及应用微信实施诈骗的犯罪情节。 对此您怎么看？快来留言区聊聊吧。返回搜狐，查看更多 责任编辑：","contentType":0,"created":1574219277306,"deleted":0,"hits":0,"hot":1,"keywords":"网易","original":"网易","status":1,"title":"早报  央行再“放水”1200亿元；最高法：微信是网络诈骗中使用最频繁的工具；港交所研究收购西班牙交易所","userId":155})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.liujian.cms.dao.ArticleMapper.insertSelective-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article      ( title,                              channel_id,                       category_id,                       user_id,                       hits,                       hot,                       status,                       deleted,                       created,                              content,                               content_type,                          keywords,                          original )       values ( ?,                              ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                              ?,                               ?,                       ?,                          ? )
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy40.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy41.insertSelective(Unknown Source)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:47)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:30)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor195.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy81.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor194.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 15 more
ERROR - 2019-11-20 11:07:57.473; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = articles, partition = 0, offset = 2434, CreateTime = 1574219277414, serialized key size = -1, serialized value size = 12917, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"categoryId":2,"channelId":1,"content":"原标题：智造头条｜ 国务院：全面取消在华外资银行、证券公司等金融机构业务范围限制；我国首个区级全域自动驾驶可载人测试路网在河北开放 同未来道声早安【2019.11.8】 国内新闻 01 国务院：全面取消在华外资银行、证券公司、基金管理公司等金融机构业务范围限制 国务院印发的进一步做好利用外资工作的意见指出，全面取消在华外资银行、证券公司、基金管理公司等金融机构业务范围限制，丰富市场供给，增强市场活力。扩大投资入股外资银行和外资保险机构的股东范围，取消中外合资银行中方唯一或主要股东必须是金融机构的要求，允许外国保险集团公司投资设立保险类机构。 （来源：证券时报） 02 阿里巴巴香港创业基金增加对生物科技投资，想找新独角兽 11月7日消息，据港媒《南华早报》报道，阿里巴巴香港创业者基金是阿里巴巴创始人马云创立的，规模为1.31亿美元。这只基金已向20多家初创企业投资3500万美元，其中包括总部位于香港的基因检测公司Prenetics，其似乎要在生物科技领域继续复制人工智能初创企业商汤科技和金融科技公司WeLab的成功。该基金计划增加对香港生物科技初创企业的投资，这些企业可能会成为下一个独角兽，从而将基金投资重点从金融科技和人工智能领域扩展开来。 （来源：网易科技） 03 我国首个区级全域自动驾驶可载人测试路网在河北开放 河北省沧州市举行了智能网联汽车测试道路首批路网发布暨自动驾驶载人测试，30辆百度Apollo自动驾驶汽车驶上沧州经济开发区的街头，这也是我国首个区级全域自动驾驶可载人测试路网正式开放。据了解，此次百度Apollo自动驾驶车队可在沧州经济开发区内所有测试路段进行规模化载人测试，开放测试道路的里程可达114公里。区域道路路网允许全域开放测试，意味着自动驾驶车辆从固定路段测试迈向不固定路段的一个突破性尝试，实现了从线到面的实用场景探索。 （来源：新浪科技） 04 马云谈支付宝微信竞争：没微信逼迫蚂蚁就会睡懒觉 谈到支付宝与微信之间的竞争，马云表示，“蚂蚁和支付宝最应该感谢的就是微信，为什么感谢微信？如果你要打拳击，一定要和一个高手打。正因为竞争激烈，让我们练就了一身武功。” “没有微信这样的逼迫，蚂蚁的人就会睡懒觉。由于有微信这样的公司，我就可以退休。”马云表示，“我对互联网整个竞争局势来看，我还是对我的团队充满信心，因为他们年轻，他们需要有人鞭策，他们需要优秀顶级的对手，所以像微信这样的公司，我是觉得对蚂蚁是一个巨大的福报。” （来源：网易科技） 05 百度文库推出“文源计划”，AI反盗版、反查重 11月7日消息，今日百度文库与首都版权产业联盟等单位联合推出版权保护“文源计划”，为内容创作者提供版权认证、版权扶持、版权保护的全链条服务。据了解，今后，内容创作者可在百度文库为原创作品申请版权服务，审核通过后，即可获得版权认证、流量扶持、收入扶持、法务扶持等各项版权服务及权益。百度知识垂类总经理阮瑜表示：“我们希望通过‘文源计划’，充分发挥各方优势，保障优质内容生产者的权益，借助百度的AI技术和平台资源扶持优质内容生产者，开启文档行业版权保护的新局面，助推内容版权生态更加健康繁荣的发展。” （来源：网易科技） 06 vivo与三星联合研发双模5G芯片，X30系列率先搭载 11月7日消息，vivo联合三星举行了双模5G AI芯片媒体沟通会。在沟通会上展示了双方联合研发的双模5G芯片——Exynos 980。据了解，首款搭载该芯片的vivo X30系列将在12月份发布。vivo副总裁周围表示，vivo与三星相互配合，保证开发进度和效率，整体进度提前了2-3个月，让搭载这颗芯片的双模5G手机，在年内就能和消费者见面。 （来源：网易科技） 07 雷军内部信通报嘉奖小米相机部：已登上世界之巅 小米集团创始人雷军下发全员内部信，嘉奖小米相机部。此前刚刚发布不久的全球首款1亿像素手机小米CC 9 Pro相机获得了DXOMARK相机评分121分，与华为Mate 30 Pro并列全球第一名。雷军在内部信中称：“这是我们在手机核心技术上的又一次重大突破，是我们内部了不起的伟大成就，标志着小米手机的相机技术已经无可争议地登上了世界之巅。”雷军还称，今年上半年小米研发投入同比增加了30%，小米的研发成果即将进入更猛烈的井喷期。小米在相机、快充、无线快充、屏下摄像头、手机系统等诸多领域进步斐然、大放异彩，还有不少激动人心的产品也即将出炉，感谢全公司所有的研发团队。 （来源：新浪科技） 01 盖茨：反垄断案让我分心，不然微软定能打败安卓 11月7日消息，据国外媒体报道，微软创始人比尔·盖茨（Bill Gates）表示，如果微软没有卷入美国司法部从1998年到2000年对其展开的反垄断调查，他认为现在每个人都会使用Windows Mobile操作系统。今天早些时候，盖茨在《纽约时报》举办的DealBook Conference上发表讲话，透露了他对微软智能手机操作系统所犯错误的看法。这并不是盖茨第一次反思微软在移动领域的困境。今年早些时候，盖茨称输给Android是他“有史以来最大的错误”，承认损失价值4000亿美元。 （来源：网易科技） 02 马斯克：SpaceX星际飞船未来发射成本仅200万美元 11月7日消息，据外媒报道，美国太空探索技术公司SpaceX首席执行官埃隆·马斯克(Elon Musk)日前表示，拥有了真正可重复使用的火箭，该公司星际飞船（Starship）每次发射成本只需200万美元。马斯克表示，只能使用一次的消耗性运载火箭，看起来就像是航空公司在每次完成飞行时丢掉他们的客机，而可重复使用的火箭则可以节省巨额成本。SpaceX在打造可重复使用火箭方面取得了很大进展，现在经常使用回收的二手猎鹰9号火箭和运货飞船执行任务。与此同时，该公司现在也正在建造能重复使用多次的星际飞船。 （来源：腾讯科技） 03 报道称光刻机对中国延迟出货，ASML回应称说法有误 11月7日消息，今日日经新闻（NIKKEI）报道称，荷兰ASML公司去年4月份收到了中国最大的晶圆代工厂中芯国际的订单，一台价值超过1.2亿欧元的EUV光刻机，预计今年底交货，2020年正式安装，但ASML公司迫于美国的压力暂停交付中芯国际这台EUV光刻机。ASML表示，对全球客户一视同仁。根据瓦圣纳协议，ASML出口EUV到中国需取得荷兰政府的出口许可（export license）。该出口许可于今年到期，ASML已经于到期前重新进行申请，目前正在等待荷兰政府核准。 （来源：网易科技） 04 日本10列浸水新干线列车全部报废，损失9.5亿元 据日本媒体报道，东日本铁路公司社长深泽祐二在记者会上表示，在上月台风“海贝思”袭击日本时严重浸水的10列新干线列车将全部报废，损失可能高达148亿日元(约合9.5亿元人民币)。深泽祐二说，受“海贝思”影响，北陆新干线有10列列车浸水。虽然部分列车零部件还可以使用，但是考虑到列车运行的稳定性、安全性以及维修的费用，还是应当重新建造新列车。 （来源：腾讯科技） 05 丰田与铃木在印度成立合资公司，开展汽车拆解回收业务 丰田汽车与铃木汽车将合作在印度成立一家汽车拆解回收公司Maruti Suzuki Toyotsu India Private Limited，该合资公司由Maruti Suzuki印度有限公司和丰田通商集团共同拥有，双方分别拥有50％的股权。诺伊达的工厂将是MSTI的第一家工厂，该单位预计初始每月拆卸约2000辆汽车，合资公司将在印度各地增加更多此类工厂。 （来源：未来汽车日报） 投融资 01 两年累积500万用户，「熊猫不走蛋糕」获数千万元Pre-A轮融资 烘焙品牌“熊猫不走”近日完成数千万元Pre-A轮融资，投资方为头头是道基金。融资后，资金将用于新城市拓展和人才体系的搭建。熊猫不走蛋糕于2017年成立于惠州，以“线上下单+仓库配送”的模式，提供生日蛋糕销售和配送服务。在不到两年的时间，迅速覆盖惠州、佛山、番禺、珠海、中山、东莞、成都、厦门、长沙、重庆等10座城市，拥有近 500 万用户，单月营收过 3000 万，并以每个月超过25%的速度增长。据公司提供的数据，人均购买次数达到每年4.1次/人。 （来源：36氪） 02 MCN「大鹅文化」完成 A+ 轮融资，投资方为腾讯兴趣内容基金 直播经纪公司 & MCN「大鹅文化」近期完成 A+ 轮融资，由腾讯兴趣内容基金（TOPIC基金）独家投资，据悉该轮融资估值超10亿人民币。 去年公司曾获得来自盛大游戏领投的一亿元A轮融资。「大鹅文化」于 2017 年 3 月成立于上海，定位于“游戏主播经纪+MCN机构”，拆解来看就是“游戏KOL签约-培养包装-内容产出-推广分发”的完整体系的搭建，直播和短视频为大鹅文化内容渠道的主要阵地。目前公司主要聚焦的游戏是王者荣耀、绝地求生和腾讯吃鸡手游—和平精英。 （来源：36氪） 03 冻品汇完成近亿元A+轮融资，招商局资本领投原创 冻品产业互联网平台“冻品汇”近日宣布完成近亿元A+轮融资，由招商局资本领投。据了解，本轮融资资金将主要用于市场扩张和提升服务水平。冻品汇隶属于重庆戈云沃网络科技有限公司，是一家冻品供应链整合服务平台，专注于为终端商户提供冻品采购服务，通过线上和线下对冻品供应链进行数字化升级和重构，形成供应链的线上、线下协同，打造冻品产业生态圈，提升冻品行业商品流通效率及服务水平。 （来源：钛媒体） 04 BitMax宣布战略投资链想家 BTMX.com(BitMax.io)宣布战略投资链想家，双方通过布局区块链教育，与一流学府、世界知名专利技术方、传统金融机构合作，打通进入区块链世界的大门，让各阶层的机构个人都能学到属于自己的区块链知识，提高认知，理性决策。BTMX.com（BitMax.io）是以产品创新引领行业的数字资产交易平台，由华尔街资深量化交易团队打造。链想家是专业的区块链教育新媒体平台，通过在高校、政府等机构布道区块链，为大众普及区块链知识。 （来源：聚金数据） 05 平方和科技完成A轮融资，该轮融资由博远资本投资 平方和科技完成A轮融资，该轮融资由博远资本投资。据了解，平方和科技公司成立于2018年，是一家工业4.0解决方案提供商，以机器视觉核心技术为主导，为用户提供云视觉架构方案，同时帮助用户解决工业流水线自动化生产的问题。投资方博远资本（BioTrack Capital）成立于2017年，是一家专注于投资和孵化中国医疗健康创业企业的专业投资机构。 （来源：亿欧网） 06 获近千万元天使轮融资，「维妥科技」要做直播电商的数据中台 直播电商数据中台服务商“维妥科技”已于今年 7 月完成近千万元天使轮融资，领投方为梅花创投，种子轮投资方英诺天使基金追加投资。维妥科技2018 年底立项，成立于2019 年 ，是一家直播电商数据中台服务商，主营业务为通过公开信息收集为内容电商提供数据营销服务，围绕数据与匹配生态提高电商营销效率。创始团队包括海归创业者、复旦系技术团队、美国数据分析团队等，团队成员先后在百度、联想、华坤道威、英国高临咨询、美国twosigma量化对冲基金等企业担任重要岗位。 （来源：投资界） 洪泰智造返回搜狐，查看更多 责任编辑：","contentType":0,"created":1574219277414,"deleted":0,"hits":0,"hot":1,"keywords":"网易","original":"网易","status":1,"title":"智造头条｜ 国务院：全面取消在华外资银行、证券公司等金融机构业务范围限制；我国首个区级全域自动驾驶可载人测试路网在河北开放","userId":155})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.liujian.cms.dao.ArticleMapper.insertSelective-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article      ( title,                              channel_id,                       category_id,                       user_id,                       hits,                       hot,                       status,                       deleted,                       created,                              content,                               content_type,                          keywords,                          original )       values ( ?,                              ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                              ?,                               ?,                       ?,                          ? )
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy40.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy41.insertSelective(Unknown Source)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:47)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:30)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor195.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy81.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor194.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 15 more
ERROR - 2019-11-20 11:07:58.442; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = articles, partition = 0, offset = 2488, CreateTime = 1574219278090, serialized key size = -1, serialized value size = 3462, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"categoryId":2,"channelId":1,"content":"原标题：浦江黄心猕猴桃，皮薄又多汁，大人小孩抢着吃！ 关于猕猴桃，一直都有种说法：绿心酸、红心甜、黄心又香又甜！ 可以说，凡是吃过黄心猕猴桃的人，都会被它所折服。 用勺子轻轻一挖，诱人的果肉里爆出丰沛的汁水，不会太甜，也不会太酸，甜酸比例刚刚好！ 细腻的果肉，用舌头轻轻一抿就化了，满口兜不住的汁水，浓香四溢的口感，足以令人忘却一切的烦恼。 市面上的猕猴桃种类繁多，品质也是参差不齐，但只有不打药、不催熟，树上自然成熟的猕猴桃才zui好吃。 莞报君推荐的这家浦江黄心猕猴桃都是树上自然成熟，不熟不摘，是基地多年坚守的准则。 虽然猕猴桃外表看不出来成熟度，但口感却千差万别，我们坚持树上熟，追求口感zui佳期，只希望当你品尝的那一刻，满心欢喜！ 莞报君推荐的3大理由👇 1 清甜香软、肉厚多汁、肉质细腻爽滑； 2 产自猕猴桃的黄金种植区，专业种植，树上成熟； 四川蒲江，一直是猕猴桃zui佳种植区。 这里气候温和、雨量充沛、土壤肥沃，特别适合猕猴桃的种植 也是少有的同时种有绿心、红心、黄心三种猕猴桃的产区之一。 2010年国际猕猴桃高峰论坛在蒲江举行。 因为重视品质，这里： 果树灌溉水源都是山泉水，保证安全无污染； 只采用人工除草方式，从不使用除草剂； 施肥以农家肥，坚决不使用超标农药…… 挑一个已经软了的猕猴桃，对半切开，立即露出里面香甜的果肉，忍不住咬一口，软糯香甜，一口接一口根本停不下来。 黄心猕猴桃直接吃好吃，搭配酸奶口感更好！ 蒲江黄心猕猴桃 新鲜现摘 蜜甜多汁 猕猴桃富含维生素C， 100g猕猴桃中的维C含量约为62毫克。 成熟的黄心猕猴桃，圆润饱满，对半切开用勺子挖着吃，肉厚汁水足，咬一口甜到心尖。就连平时挑食不爱吃水果的小孩，都会忍不住多吃几个。 为了减少运输造成的损伤，我们都是新鲜采摘7-8成熟的猕猴桃，摸上去还有点硬。 和苹果或香蕉一起放3-5天，便可以自然催熟。拿在手上，轻轻一捏两头感到柔软的时候，吃起来口感zui佳。 为了保您收到时完好无损，整箱包装采用网格保护，每颗都会经过仔细挑选，个头大小均匀，包装规整上档次，不管自己吃还是送人都特别合适。 食用小贴士： 猕猴桃属后熟果，需要放置成熟或催化成熟方可食用。 1.催熟办法：可将猕猴桃与其它水果（香蕉、苹果、梨）混放，密封3-5天，可使猕猴桃提前自然软熟。 2.放置时间：如果使用放置成熟的方法，时间并不一定。可用手指轻轻按压猕猴桃的两端附近，按压处若有轻微变形，但又不是太软，就是最佳食用状态。 食用方法： 阴凉处10-20度常温下，可保存一星期左右。对半切开，用勺挖食或直接削皮食用。 点击阅读原文立即购买 广告 本期编辑 |邹文丽返回搜狐，查看更多 责任编辑：","contentType":0,"created":1574219278090,"deleted":0,"hits":0,"hot":1,"keywords":"网易","original":"网易","status":1,"title":"浦江黄心猕猴桃，皮薄又多汁，大人小孩抢着吃！","userId":155})
org.springframework.jdbc.UncategorizedSQLException: 
### Error updating database.  Cause: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1
### The error may involve com.liujian.cms.dao.ArticleMapper.insertSelective-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article      ( title,                              channel_id,                       category_id,                       user_id,                       hits,                       hot,                       status,                       deleted,                       created,                              content,                               content_type,                          keywords,                          original )       values ( ?,                              ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                              ?,                               ?,                       ?,                          ? )
### Cause: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1
; uncategorized SQLException; SQL state [HY000]; error code [1366]; Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1; nested exception is java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:89)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy40.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy41.insertSelective(Unknown Source)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:47)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:30)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.sql.SQLException: Incorrect string value: '\xF0\x9F\x91\x87 1...' for column 'content' at row 1
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:1055)
	at com.mysql.jdbc.SQLError.createSQLException(SQLError.java:956)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3491)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor195.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy81.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor194.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 15 more
ERROR - 2019-11-20 11:07:58.533; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = articles, partition = 0, offset = 2499, CreateTime = 1574219278225, serialized key size = -1, serialized value size = 10406, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"categoryId":2,"channelId":1,"content":"原标题：滴滴顺风车 3 城试运营；美商务部第三次延长可采购华为设备期限；传阿里将香港 IPO 价格指引定在每股 176 港元左右 滴滴顺风车今早 9 点 3 城试运营，用户需完成安全任务 11 月 19 日消息，滴滴顺风车在滴滴出行 App 内更新试运营公告，宣布 11 月 20 日，顺风车将在哈尔滨、太原、常州 3 个城市上线试运营。当地的用户需要首先在端内完成安全任务，才可以使用顺风车服务。 同时，公告还说明，因技术调试原因，原定第一批试运营的北京和石家庄，将延缓至 12 月。即 11 月 20 日上午 9:00，在哈尔滨、太原、常州上线，11 月 29 日上午 9:00 在 沈阳、南通上线。试运营期间，将首先提供 5:00-20:00、市内中短途（50 公里以内）的顺风车平台服务，试运营期间不收取信息服务费。（来源：网易科技） 消息称阿里将香港 IPO 价格指引定在每股 176 港元左右 北京时间 11 月 20 日，据彭博社报道，阿里巴巴据称将香港 IPO 价格指引定在每股 176 港元左右。 阿里巴巴集团控股有限公司 15 日宣布，当日正式启动香港上市。公司将在香港交易所主板上市，股份代号为 9988。阿里本次将发行 5 亿股普通股新股，其中香港公开发售 0.125 亿股新股，发行价格将不高于每股 188 港元；国际发售 4.875 亿新股，将于 20 日确定国际发售价。（来源：新浪财经） 小米 CEO 雷军：将于 2020 年推出至少 10 款 5G 手机 11 月 19 日，在小米开发者大会上，雷军表示：去年今年手机开始巨量下滑，用户群期待 5G 带来的新改变。明年是 5G 市场起飞的元年，相信换机潮开始对国内手机市场有巨大拉动。同时，小米今年 12 月将发布第一款双模手机，为 Redmi K30，明年至少发布 10 款 5G 手机。 此外，在 AIoT 平台方面，目前小米已经接入了 2200+款产品。截至目前，小米 AIoT 连接设备数达到 1.96 亿。（来源：36Kr） 美国商务部发布 90 天延期许可，第三次延长可采购华为设备的期限 美国 NPR 18 日消息，美国商务部当日发布公告，宣布发布 90 天延期许可，允许美国企业继续与中国华为技术有限公司进行业务往来。路透社称，这是美国政府自今年 5 月把华为列入管制黑名单以来，第三次延长期限。 NPR 称，在美国乡村地区，许多电信运营商购买华为设备，第三次延长期限意味着这些企业可以继续采购华为公司产品。美国商务部长罗斯在声明中说，「延期许可将允许电信运营商在一些美国最偏远乡村地区提供服务，否则，这些地区可能会陷入一片黑暗」。（来源：品玩） 三星效仿苹果打造年收入 500 亿美元的服务业务 11 月 19 日消息，据外媒报道，三星希望效仿苹果，打造一项年收入 500 亿美元的服务业务。三星在过去 4 年对软件进行了大量投资，一名高管表示，「现在我们正试图将我们投资的这些重大软件整合成有意义的客户体验。」 三星此举是为了在硬件部门之外寻求增长。此外，该公司尚未具体披露希望对哪些新的「客户体验」进行变现。高管们表示，只有更广泛地采用最新技术，机会才会变得清晰起来。（来源：腾讯科技） 微软团队协作程序 Teams 日活用户超 2000 万，远超 Slack 11 月 20 日，据 CNBC 报道，微软周二表示，其 Teams 通讯应用程序现在每天有超过 2000 万活跃用户，比微软先前宣布的使用量增长了近 54％，领先于 Slack。Slack 在 10 月表示，其应用每天有 1200 万活跃用户。 在微软宣布这一消息后，Slack 的股价周二下跌了 10％，收盘时下跌了 8.4％。自公司 6 月份在公众市场首次公开募股以来，股价已下跌超过 18％，较首日高位下跌近 50％。（来源：品玩） 京东：未来三年将累计发布 1 亿种新品及 C2M 产品 11 月 19 日，京东 2019 年全球科技探索者大会召开。会上，京东零售集团 CEO 徐雷表示，京东 C2M 模式将产品需求调研时间减少了 75%，新品上市周期缩短了 67%，未来京东将发布一亿种新品及 C2M 产品，创新含量高的品类占比达到 70%。而该系统作为公司级重要项目，物竞天择的目标是未来实现年千亿级的交易额。（来源：36Kr） 盒马新业态「盒马里」将于 11 月 23 日试营业：主打一站式送餐 11 月 19 日，盒马 CEO 侯毅确认，首家「盒马里」将于 11 月 23 日在深圳莲塘试营业，30 日正式开业。「盒马里」为盒马旗下新业态，主打一站式送餐。目前，大目火锅、利宝阁点心、奈雪的茶、顺德双皮奶已确认入驻，各家的招牌菜可在盒马 App 下单，一站式配送，无需配送费。盒马方面还宣称，还有不少新服务会在即将开业的盒马里购物中心亮相。（来源：腾讯一线） 滴滴成立传媒公司，涉足电视剧制作、电影发行 天眼查数据显示，11 月 12 日，滴滴出行的运营主体北京小桔科技有限公司新增对外投资信息，出资 1000 万元成立北京粒粒橙传媒有限公司。北京粒粒橙传媒有限公司法定代表人为滴滴市场部负责人王嘉杰，经营范围包括电视剧制作、音像制品制作、电子出版物制作、电影发行等，由北京小桔科技有限公司全资控股。（来源：凤凰网科技） 特斯拉国产 Model 3 三日后到店，起售价 35.58 万元 据报道，标配基础版辅助驾驶功能的特斯拉 Model 3 标准续航升级版（中国制造）车型将于 11 月 22 日全面到店，起售价为人民币 35.58 万元。届时全国消费者可以登陆特斯拉中国官网 tesla.cn 或前往各地特斯拉体验中心进行咨询或体验。 据介绍，Model 3 标准续航升级版（中国制造）续航里程为 460 公里（NEDC 预估），0-100 公里/小时加速时间最快仅需 5.6 秒，最高时速为 225 公里/小时。（来源：智通财经） 法拉第未来 CEO：人们对公司执行力和贾跃亭缺乏信任 法拉第未来（Faraday Future）CEO 卡斯滕·布雷菲尔德 11 月 20 日表示，法拉第未来面临两大障碍。第一个问题是人们对公司执行计划的能力缺乏信任。第二个问题是公司创始人贾跃亭的领导也存在着问题。布雷菲尔德称，第一个问题已经解决，贾跃亭接下来的工作将是将专注于 FF 汽车的连通性和用户体验，旨在将其打造成人们的「第三生活空间」。（来源：新浪财经） 京东发布配送机器人 4.0，2020 年将在开放路段正式运营 11 月 19 日，京东集团副总裁、X 事业部总裁肖军透露，京东配送机器人 4.0 将于 2020 年正式投入使用。 配送机器人 4.0 将搭配 L4 级自动驾驶配送车，拥有远程接管模式，货箱容量 1024 升，空载重量 350kg，承载重量 150kg，最大速度 km/h，续航里程 100km，最大爬坡 30%。并可改造成无人小巴、无人巡检车、无人观光车和无人接驳车等多功能无人驾驶车辆。（来源：DoNews） Oculus Link Beta 版上线，公布官方推荐线缆 11 月 19 日，Oculus 正式公布 Oculus Link Beta 上线，这意味着测试者通过一根 USB Type C 线缆连接 PC，即可体验更庞大的 PC VR 内容库，Quest 用户也能体验 Rift 内容。 早在 OC6 大会时，Oculus 官网表示将推出官方高品质光纤线缆（售价为 79 美元），但目前仍未发布。但此前已向配件厂商开放此线缆规格标准，并正式公布，并给出部分线缆推荐，比如 Anker Powerline USB-C 转 USB 3.0（3 米），型号为 AK-A8167011，售价 13 美元。（来源：青亭网） 中国首个天基互联网系统将于明年投入示范应用 11 月 19 日，中国国际商业航天高峰论坛在湖北武汉举行。记者从论坛上获悉，我国首个天基互联网系统——「虹云工程」将于明年投入示范应用。虹云工程将由一百多颗小卫星组成，在未来组网完成后，人们将能够在世界任何角落接入宽带互联网。 「虹云工程」规划建设由一百多颗互联网卫星组成的星座，它们在距离地面 1000 公里的轨道上组网运行，构建一个天基宽带全球移动互联网络，建成后将实现全球无死角的互联网接入服务。 虹云工程技术验证星自 2018 年 12 月成功发射入轨后，完成了不同天气条件、不同载体、不同业务场景下的功能与性能测试，成功实现了网页浏览、微信发送、视频聊天、高清视频点播等典型互联网业务，据介绍，虹云工程首个应用示范系统将于 2020 年初投入使用。按照规划，虹云工程明年还将发射 4 颗业务试验星，通过组网完成区域覆盖。（来源：央视新闻） 滴滴副总裁郄小虎：很快在上海推出自动驾驶叫车服务 11 月 19 日，滴滴出行副总裁、网约车部门 CTO 郄小虎，在 CNBC 于广州举办的「East Tech West」（东西方科技对话）会议上称：「我们很快就会在上海推出一项自动驾驶出租车服务，用户可以通过滴滴出行 App 呼叫自动驾驶汽车。」 郄小虎表示，滴滴出行目前只能满足 65% 的用户乘车要求，而自动驾驶汽车的推出将有助于填补这一供需缺口。他补充说，部署自动驾驶车辆并不意味着将放弃人类驾驶。郄小虎说：「自动驾驶车辆和人工驾驶车辆将共存。」 滴滴出行成立于 2012 年，此后发展迅速，如今已有 5.5 亿用户在其平台上注册。2016 年，滴滴出行还接管了 Uber 的中国业务。近期，该公司又开始向海外扩张，包括进入澳大利亚和墨西哥等国。（来源：新浪科技）返回搜狐，查看更多 责任编辑：","contentType":0,"created":1574219278225,"deleted":0,"hits":0,"hot":1,"keywords":"网易","original":"网易","status":1,"title":"滴滴顺风车 3 城试运营；美商务部第三次延长可采购华为设备期限；传阿里将香港 IPO 价格指引定在每股 176 港元左右","userId":155})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.liujian.cms.dao.ArticleMapper.insertSelective-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article      ( title,                              channel_id,                       category_id,                       user_id,                       hits,                       hot,                       status,                       deleted,                       created,                              content,                               content_type,                          keywords,                          original )       values ( ?,                              ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                              ?,                               ?,                       ?,                          ? )
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy40.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy41.insertSelective(Unknown Source)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:47)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:30)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor195.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy81.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor194.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 15 more
ERROR - 2019-11-20 11:07:58.551; org.springframework.kafka.listener.LoggingErrorHandler; Error while processing: ConsumerRecord(topic = articles, partition = 0, offset = 2502, CreateTime = 1574219278252, serialized key size = -1, serialized value size = 10396, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = {"categoryId":2,"channelId":1,"content":"原标题：滴滴顺风车调整运营时段；阿里确定下周开始路演；Uber CEO 为公司业务辩护，称与 WeWork 截然不同 滴滴：对所有顺风车用户服务时间均调为 5:00-20:00 11 月 7 日消息，滴滴宣布，决定对顺风车规则进行调整，在顺风车小范围试运营期间，对所有顺风车用户提供服务的时间均调整为 5:00-20:00。试运行期间（不收信息服务费），产品服务规则可能还会不断迭代优化。滴滴表示，根据顺风车过往安全投诉数据统计，20:00-23:00、23:00-5:00 两个时间段，涉性类投诉数量比 5:00-20:00 分别高 45% 和 465%。（来源：澎湃新闻） 阿里确定下周开始路演，以 4% 折扣向机构询价 11 月 8 日消息，《一线》获悉阿里巴巴确定下周开始在香港进行上市前的路演。这个星期阿里巴巴已经开始与部分香港的机构投资者进行沟通。阿里巴巴上市团队已经与一些机构投资者沟通了关于定价折扣的内容，并以现在美股价格 4% 的折扣进行询价。截止 11 月 7 日，阿里巴巴在美股收盘价为 186.66 美元每股。（来源：腾讯一线） Uber CEO 为公司业务辩护，称与 WeWork 截然不同 11 月 7 日消息，在《纽约时报》的 DealBook 大会上，达拉·科斯罗萨西被问及，他是否对公司及时上市避免了像 WeWork 这样的情况而感到高兴。科斯罗萨西表示：「我们与 WeWork 截然不同。从根本上讲，拼车市场已经颇具规模，是全球性的市场，是一项有吸引力的业务，而且只会在竞争日益激烈的市场中变得更好。」科斯罗萨西在舞台上承认，Uber 已经感受到了公共和私人投资者对其怀疑的影响。但他表示，这「迫使 Uber 表现得更好」。该公司宣布预计在 2021 年实现 EBITDA 盈利。（来源：腾讯科技） 比亚迪和丰田将就纯电动汽车研究建立合资公司 11 月 7 日消息，丰田汽车公司与比亚迪股份有限公司就成立纯电动车的研发公司签订合资协议。新公司将于 2020 年在中国正式成立，丰田与比亚迪各出资 50%。新公司将开展纯电动车及该车辆所用平台、零件的设计、研发等相关业务。从比亚迪内部人士处获悉，双方正在探讨合资公司由丰田派出董事长、比亚迪派出总经理等人事安排细节问题。（来源：36Kr、财联社） OYO 回应「修改业主规则」：不影响业主合同中保底金额 11 月 7 日消息，针对媒体报道的「OYO酒店修改业主相关规则」一事，OYO 方面回应称，基于 OYO 已经投入了 7 亿元用于为酒店业主提升基础设施，并提供线下需求拓展、酒店管理系统（PMS）、收益管理系统等，OYO 酒店将为这些服务适当调整费用。同时，这些调整将不会影响业主签售合同中的保底金额。 此前，媒体报道称，OYO 近期为了盈利压力修改了中国业主相关规则细节：给住客的优惠券改为由业主承担，而其按惯例应由平台承担；如果发生投诉等问题会对业主罚款甚至扣保底，罚款力度加大。（来源：新浪科技） B 站回应「UP 主带粉丝薅垮店铺」：已封禁其站内账号 11 月 7 日消息，就 B 站 UP 主「路人 A-」带粉丝「薅羊毛」一事，B 站做出回应，称现在已封禁其站内账号，直至其妥善处理本次事件。B 站也将监督其向店家郑重道歉，并协助其配合天猫平台处理此事。 近日，一淘宝店家因操作失误，误将 26 元 4500 克的脐橙写成了 4500 斤后，B 站博主「路人 A-」在直播时号召粉丝去「薅羊毛」，又在商家无法发货的情况下，恶意投诉「商家虚假宣传」，导致该店铺直接关店。（来源：网易科技） 电子烟巨头 Juul 宣布在美停售薄荷味电子烟 11 月 8 日消息，电子烟巨头 Juul Labs 宣布，将即刻停止在美国出售薄荷味电子烟，因新迹象显示此类产品在美国青少年中越来越受欢迎。本周发表在《美国医学协会期刊》上的研究发现，薄荷味电子烟是美国 10 年级至 12 年级（高中）用户中最受欢迎的产品，超过 40% 的受访者表示这是他们最常用的电子烟品种。（来源：新浪科技） 游族与华为达成长期合作，开拓云游戏市场 11 月 7 日消息，游族与华为签署合作框架协议，双方将联手开展云游戏合作，共同开拓云游戏行业市场。华为提供云游戏基础技术平台和相关业务模块，支持游族结合自身游戏技术优势和业务模块进行整体优化，同时为游族在游戏研运、人工智能、云计算、5G 创新等新技术应用方面提供方案和建议。后续双方将共同推进云游戏解决方案并发布云游戏产品，包括 ARM 安卓云游戏和 PC 云游戏等。（来源：中国证劵网） 摩根大通上调京东目标价至 42 美元，重申对京东的增持评级 11 月 7 日消息，摩根大通上调京东目标价至 42 美元，并重申对京东的增持评级。摩根大通发布分析报告称，京东第二季度至今股价已上涨 10%，涨幅略高于阿里巴巴和 MSCI 中国指数的 6％。摩根大通预测第三季度在非美国通用会计准则下，京东的净利润将超出市场预期 30%。（来源：36Kr） 新东方旗下多纳外教直播课将停止运营 11 月 7 日，新东方多纳外教学堂发布公告称，因新东方在线课程体系升级，多纳外教直播课程决定于 2020 年 5 月 31 日起停止运营。2016 年 1 月 9 日，北京新东方学校发布多纳学科英语。根据官网，新东方多纳外教学堂是新东方旗下在线少儿英语品牌专为 4-12 岁孩子提供少儿英语课程。今年 8 月 1 日，「新东方多纳」品牌创建人陈婉青宣布正式加入编程猫，出任 COO 职位。（来源：投中网） 京东天猫等 9 家电商平台已下架电子烟产品 11 月 8 日消息，关于禁止网售电子烟的新规发布后，目前已有京东、天猫、拼多多、苏宁易购等 9 家电商平台屏蔽电子烟店铺，并下架电子烟产品。也有数家电子烟企业已关闭所有电商平台店铺，实现全网产品下架。此外，监管部门还根据企业类型的不同提出了具体要求。以搜索引擎为例，除了清理和屏蔽涉及电子烟的关键词搜索，还要求清理自然搜索结果下电子烟销售的网站链接。（来源：央视） 八部委印发《关于进一步加强青少年控烟工作的通知》：全面开展电子烟危害宣传和规范管理 11 月 7 日消息，国家卫生健康委、中宣部、教育部、市场监管总局、广电总局、国家烟草局、共青团中央、全国妇联等 8 部门联合印发了《关于进一步加强青少年控烟工作的通知》。其中提到，全面开展电子烟危害宣传和规范管理，各地要主动加强对电子烟危害的宣传教育，不将电子烟作为戒烟方法进行宣传推广，倡导青少年远离电子烟。 在地方控烟立法、修法及执法中要积极推动公共场所禁止吸电子烟。要结合中小学校周边综合治理等专项行动，警示各类市场主体不得向未成年人销售电子烟，尤其是通过互联网向未成年人销售电子烟，有效防止青少年误入电子烟迷途。（来源：规划发展与信息化司） 百度上线社交 App「听筒」 11 月 7 日消息，百度在安卓应用市场上线了一款定位于年轻人社交 App「听筒」。根据应用介绍，开发者为百度在线网络技术（北京）有限公司，于 2019 年 11 月 6 日上线 1.0 版本。据介绍，听筒包括匿名广场、地图找人、合拍铃功能，用户可随机发布匿名动态，开启实时位置，尤其提到学校位置，可匹配邻校用户。此外，用户注册需要填写学校、城市等具体信息，支持上传校园卡/学生证/毕业证完成学校认证。目前来看，该应用主要面向高校学生群体。（来源：新浪科技） vivo 公布与三星联合研发的双模 5G AI 芯片：Exynos 980 11 月 7 日，vivo 在北京正式公布了与三星联合研发的双模 5G AI 芯片：Exynos 980。Exynos 980 芯片同时支持 NSA 和 SA 两种组网模式。Exynos 980 在 5G 通信环境即 Sub-6GHz 以下频段下，可实现最高 2.55Gbps 的下载速率，在 4G-5G 双连接（E-UTRA-NR Dual Connectivity, EN-DC）状态下，下载速率最高可达 3.55Gbps。 Exynos980 首次采用了 ARM 新一代的 Cortex-A77 CPU 架构，同频性能方面较 Cortex-A76 架构提升了 20%，确保快速处理大容量数据。配合高端 GPU Mali-G76，高清游戏轻松运行。Exynos 980 内置高性能 NPU 和 DSP 单元，实现旗舰级运算速度，同时还内置高性能 ISP，最高可处理以 1.08 亿像素拍摄的图像，与强大的 NPU 配合，可识别拍摄物体的形态、周围环境等，自动调节至更佳值，让用户轻松就能拍下效果更好的照片。（来源：PingWest） 猎豹傅盛谈公司转型，称也曾想过做汽车 11 月 7 日消息，2019 年《财富》全球科技论坛于广州开幕，猎豹移动公司联合创始人兼首席执行官傅盛参会，论述了猎豹移动转型背后的故事与思考。猎豹移动正从传统移动互联网向以 AI 驱动的产业互联网公司转型。早先，猎豹移动提出 All in AI 战略，并投资了人工智能公司猎户星空，此后发布一系列智能机器人硬件产品。 关于做机器人这件事，傅盛表示，自己想去做一个别人没有定义过的产品，「而不是别人定义过我还要重新把它做得更好一点」。他透露，「我也想过做汽车，但是我想特斯拉出来以后，电动车已经被定义了。」想来想去，最后琢磨到智能机器人。（来源：新浪科技） 图片来源：视觉中国返回搜狐，查看更多 责任编辑：","contentType":0,"created":1574219278252,"deleted":0,"hits":0,"hot":1,"keywords":"网易","original":"网易","status":1,"title":"滴滴顺风车调整运营时段；阿里确定下周开始路演；Uber CEO 为公司业务辩护，称与 WeWork 截然不同","userId":155})
org.springframework.dao.DataIntegrityViolationException: 
### Error updating database.  Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
### The error may involve com.liujian.cms.dao.ArticleMapper.insertSelective-Inline
### The error occurred while setting parameters
### SQL: insert into cms_article      ( title,                              channel_id,                       category_id,                       user_id,                       hits,                       hot,                       status,                       deleted,                       created,                              content,                               content_type,                          keywords,                          original )       values ( ?,                              ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                       ?,                              ?,                               ?,                       ?,                          ? )
### Cause: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
; Data truncation: Data too long for column 'title' at row 1; nested exception is com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at org.springframework.jdbc.support.SQLStateSQLExceptionTranslator.doTranslate(SQLStateSQLExceptionTranslator.java:104)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:72)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)
	at org.mybatis.spring.MyBatisExceptionTranslator.translateExceptionIfPossible(MyBatisExceptionTranslator.java:75)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:447)
	at com.sun.proxy.$Proxy40.insert(Unknown Source)
	at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:279)
	at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:57)
	at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:59)
	at com.sun.proxy.$Proxy41.insertSelective(Unknown Source)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:47)
	at com.liujian.cms.kafka.ArticleListener.onMessage(ArticleListener.java:30)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:1156)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:1115)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:1057)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:903)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:753)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.lang.Thread.run(Thread.java:745)
Caused by: com.mysql.jdbc.MysqlDataTruncation: Data truncation: Data too long for column 'title' at row 1
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3489)
	at com.mysql.jdbc.MysqlIO.checkErrorPacket(MysqlIO.java:3423)
	at com.mysql.jdbc.MysqlIO.sendCommand(MysqlIO.java:1936)
	at com.mysql.jdbc.MysqlIO.sqlQueryDirect(MysqlIO.java:2060)
	at com.mysql.jdbc.ConnectionImpl.execSQL(ConnectionImpl.java:2542)
	at com.mysql.jdbc.PreparedStatement.executeInternal(PreparedStatement.java:1734)
	at com.mysql.jdbc.PreparedStatement.execute(PreparedStatement.java:995)
	at com.alibaba.druid.pool.DruidPooledPreparedStatement.execute(DruidPooledPreparedStatement.java:493)
	at org.apache.ibatis.executor.statement.PreparedStatementHandler.update(PreparedStatementHandler.java:46)
	at org.apache.ibatis.executor.statement.RoutingStatementHandler.update(RoutingStatementHandler.java:74)
	at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:50)
	at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117)
	at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76)
	at sun.reflect.GeneratedMethodAccessor195.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.ibatis.plugin.Plugin.invoke(Plugin.java:63)
	at com.sun.proxy.$Proxy81.update(Unknown Source)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:198)
	at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:185)
	at sun.reflect.GeneratedMethodAccessor194.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:434)
	... 15 more
INFO  - 2019-11-20 11:35:34.101; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-20 11:35:38.607; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 12:57:19.121; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-20 12:57:21.665; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-20 15:01:44.029; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
INFO  - 2019-11-20 15:01:44.380; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-21 08:25:30.994; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-21 08:25:31.415; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-21 08:25:31.836; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-21 08:25:33.526; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-21 08:25:33.637; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-21 08:25:33.638; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-21 08:25:33.654; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-21 08:25:33.929; org.apache.kafka.clients.Metadata; Cluster ID: QiYF4Aq0SBC0vWy87g_CxA
INFO  - 2019-11-21 08:25:33.932; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler; [Consumer clientId=consumer-1, groupId=test-consumer-group] Discovered group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null)
INFO  - 2019-11-21 08:25:33.937; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Revoking previously assigned partitions []
INFO  - 2019-11-21 08:25:33.938; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions revoked: []
INFO  - 2019-11-21 08:25:33.939; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] (Re-)joining group
INFO  - 2019-11-21 08:25:35.763; org.apache.kafka.clients.consumer.internals.AbstractCoordinator$1; [Consumer clientId=consumer-1, groupId=test-consumer-group] Successfully joined group with generation 182
INFO  - 2019-11-21 08:25:35.765; org.apache.kafka.clients.consumer.internals.ConsumerCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Setting newly assigned partitions []
INFO  - 2019-11-21 08:25:35.766; org.springframework.kafka.listener.AbstractMessageListenerContainer$2; partitions assigned: []
INFO  - 2019-11-21 08:25:35.825; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
ERROR - 2019-11-21 08:25:38.703; org.springframework.data.elasticsearch.repository.support.AbstractElasticsearchRepository; failed to load elasticsearch nodes : org.elasticsearch.client.transport.NoNodeAvailableException: None of the configured nodes are available: [{#transport#-1}{LvBGNh_QQMu-iC5TXMJ8JQ}{192.168.18.130}{192.168.18.130:9300}]
INFO  - 2019-11-21 08:25:39.642; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 8628 ms
INFO  - 2019-11-21 08:25:39.856; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-21 08:25:40.424; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-21 08:25:40.984; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 1127 ms
INFO  - 2019-11-21 08:25:59.036; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
INFO  - 2019-11-21 08:32:14.897; org.apache.kafka.clients.consumer.internals.AbstractCoordinator; [Consumer clientId=consumer-1, groupId=test-consumer-group] Group coordinator 192.168.18.130:9092 (id: 2147483647 rack: null) is unavailable or invalid, will attempt rediscovery
WARN  - 2019-11-21 08:32:16.956; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:19.113; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:21.371; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:23.756; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:26.482; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:29.480; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:32.474; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:35.670; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:38.741; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:41.860; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:44.722; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:47.741; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:50.960; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:53.788; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:56.874; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:32:59.748; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:02.920; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:05.813; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:08.725; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:11.746; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:14.604; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:17.512; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:20.673; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:23.736; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:26.598; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:29.575; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:32.766; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:35.933; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:38.914; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:41.771; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:44.977; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:48.026; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:51.206; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:54.139; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:33:57.267; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:00.256; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:03.141; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:06.084; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:08.967; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:12.137; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:15.250; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:18.264; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:21.336; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:24.506; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:27.574; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:30.741; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:33.753; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:36.815; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:39.932; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:43.004; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:46.067; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:49.183; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:52.356; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:55.517; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:34:58.426; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:01.638; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:04.647; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:07.508; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:10.419; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:13.480; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:16.545; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:19.559; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:22.570; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:25.582; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:28.443; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:31.458; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:34.519; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:37.441; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:40.350; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:43.210; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:46.067; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:48.931; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:51.839; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:54.748; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:35:57.577; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:00.736; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:03.748; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:06.808; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:10.022; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:13.189; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:16.266; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:19.255; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:22.474; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:25.492; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:28.356; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:31.494; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:34.663; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:37.577; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:40.742; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:43.608; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:46.518; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:49.375; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:52.589; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:55.801; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:36:58.861; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:01.876; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:04.886; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:08.099; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:11.267; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:14.383; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:17.354; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:20.425; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:23.384; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:26.496; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:29.712; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:32.623; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:35.756; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:38.727; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:41.633; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:44.801; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:47.971; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:50.837; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:53.705; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:56.917; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:37:59.928; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:02.940; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:05.850; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:08.764; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:11.881; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:15.099; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:18.166; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:21.327; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node 0 could not be established. Broker may not be available.
INFO  - 2019-11-21 08:38:42.637; org.springframework.web.context.ContextLoader; Root WebApplicationContext: initialization started
INFO  - 2019-11-21 08:38:42.873; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-21 08:38:43.179; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
INFO  - 2019-11-21 08:38:44.331; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-21 08:38:44.419; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-21 08:38:44.420; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-21 08:38:44.430; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
INFO  - 2019-11-21 08:38:46.081; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
WARN  - 2019-11-21 08:38:46.606; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2019-11-21 08:38:47.688; org.springframework.web.context.ContextLoader; Root WebApplicationContext initialized in 5048 ms
INFO  - 2019-11-21 08:38:47.772; org.springframework.web.servlet.FrameworkServlet; Initializing Servlet 'springDispatcherServlet'
INFO  - 2019-11-21 08:38:48.087; org.hibernate.validator.internal.util.Version; HV000001: Hibernate Validator 5.1.0.Final
INFO  - 2019-11-21 08:38:48.386; org.springframework.web.servlet.FrameworkServlet; Completed initialization in 614 ms
WARN  - 2019-11-21 08:38:48.682; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:50.851; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:53.081; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:55.438; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:38:58.351; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:01.420; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:04.636; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:07.851; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2019-11-21 08:39:10.651; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2019-11-21 08:39:11.015; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:14.083; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:17.064; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:20.029; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:22.941; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:25.911; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:28.920; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:32.031; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:35.242; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:38.160; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:41.276; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:44.188; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:47.154; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:50.122; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:53.331; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:56.344; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:39:59.257; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:02.315; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:05.276; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:08.335; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:11.449; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:14.559; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:17.669; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:20.841; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:24.071; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:26.932; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:29.997; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:33.068; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:36.292; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:39.416; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:42.429; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:45.646; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:48.757; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:51.664; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:54.775; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:40:57.650; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:00.683; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:03.903; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:06.816; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:09.676; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:12.838; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:15.694; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:18.856; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:22.018; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:24.935; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:27.865; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:30.731; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:33.593; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:36.504; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:39.519; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:42.381; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:45.490; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:48.507; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:51.415; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:54.379; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:41:57.395; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:00.517; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:03.574; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:06.536; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:09.395; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:12.263; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:15.428; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:18.290; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:21.253; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:24.119; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:27.286; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:30.460; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:33.622; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:36.529; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:39.643; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:42.804; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:45.760; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:48.719; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:51.933; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:55.096; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:42:58.010; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:01.133; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:04.249; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:07.256; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:10.164; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:13.171; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:16.179; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:19.216; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:22.377; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:25.249; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:28.074; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:31.086; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:33.996; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:37.060; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:40.067; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:42.977; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:46.183; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:49.294; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:52.310; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:55.438; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:43:58.521; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:01.457; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:04.582; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:07.445; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:10.366; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:13.286; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:16.450; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:19.314; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:22.290; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:25.307; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:28.524; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:31.745; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:34.810; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:37.886; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:40.745; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:43.809; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:46.976; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:50.089; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:53.006; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:55.974; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:44:59.152; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:02.067; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:05.233; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:08.347; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:11.360; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:14.470; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:17.475; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:20.686; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:23.709; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:26.693; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:29.511; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:32.538; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:35.450; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:38.317; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:41.435; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:44.654; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:47.871; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:50.788; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:53.805; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:56.770; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:45:59.881; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:02.946; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:05.887; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:09.081; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:12.000; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:15.181; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:18.357; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:21.572; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:24.637; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:27.602; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:30.725; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:33.785; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:36.943; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:39.951; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:42.886; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:45.815; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:48.937; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:51.971; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:54.887; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:46:57.699; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:00.762; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:03.934; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:06.943; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:09.903; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:13.116; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:16.181; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:19.164; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:22.235; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:25.480; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:28.599; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:31.463; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:34.655; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:37.734; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:40.698; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:43.571; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:46.446; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:49.575; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:52.487; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:55.708; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:47:58.830; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:02.028; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:05.001; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:08.213; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:11.440; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:14.559; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:17.422; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:20.387; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:23.504; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:26.425; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:29.346; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:32.331; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:35.559; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:38.431; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:41.462; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:44.343; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:47.516; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:50.689; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:53.813; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:56.865; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:48:59.836; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:03.002; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:06.136; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:09.269; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:12.248; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:15.237; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2019-11-21 08:49:16.434; org.springframework.test.context.support.AbstractTestContextBootstrapper; Loaded default TestExecutionListener class names from location [META-INF/spring.factories]: [org.springframework.test.context.web.ServletTestExecutionListener, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener, org.springframework.test.context.support.DependencyInjectionTestExecutionListener, org.springframework.test.context.support.DirtiesContextTestExecutionListener, org.springframework.test.context.transaction.TransactionalTestExecutionListener, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener]
INFO  - 2019-11-21 08:49:16.453; org.springframework.test.context.support.AbstractTestContextBootstrapper; Using TestExecutionListeners: [org.springframework.test.context.web.ServletTestExecutionListener@17579e0f, org.springframework.test.context.support.DirtiesContextBeforeModesTestExecutionListener@4d41cee, org.springframework.test.context.support.DependencyInjectionTestExecutionListener@3712b94, org.springframework.test.context.support.DirtiesContextTestExecutionListener@2833cc44, org.springframework.test.context.transaction.TransactionalTestExecutionListener@33f88ab, org.springframework.test.context.jdbc.SqlScriptsTestExecutionListener@27a8c74e]
INFO  - 2019-11-21 08:49:16.956; org.springframework.data.repository.config.RepositoryConfigurationDelegate; Multiple Spring Data modules found, entering strict repository configuration mode!
WARN  - 2019-11-21 08:49:17.604; org.mybatis.spring.mapper.ClassPathMapperScanner; Skipping MapperFactoryBean with name 'articleRepository' and 'com.liujian.cms.dao.ArticleRepository' mapperInterface. Bean already defined with the same name!
WARN  - 2019-11-21 08:49:18.398; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2019-11-21 08:49:18.807; org.apache.kafka.common.config.AbstractConfig; ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [192.168.18.130:9092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test-consumer-group
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 15000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.StringDeserializer

INFO  - 2019-11-21 08:49:18.892; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka version : 2.0.0
INFO  - 2019-11-21 08:49:18.892; org.apache.kafka.common.utils.AppInfoParser$AppInfo; Kafka commitId : 3402a8361b734732
INFO  - 2019-11-21 08:49:18.892; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Initializing ExecutorService
WARN  - 2019-11-21 08:49:21.261; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:21.511; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2019-11-21 08:49:22.624; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; adding transport node : 192.168.18.130:9300
WARN  - 2019-11-21 08:49:23.327; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:24.400; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2019-11-21 08:49:24.563; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} inited
WARN  - 2019-11-21 08:49:25.446; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:27.665; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:30.090; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:32.917; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
WARN  - 2019-11-21 08:49:35.787; org.apache.kafka.clients.NetworkClient; [Consumer clientId=consumer-1, groupId=test-consumer-group] Connection to node -1 could not be established. Broker may not be available.
INFO  - 2019-11-21 08:49:37.894; org.springframework.scheduling.concurrent.ExecutorConfigurationSupport; Shutting down ExecutorService
INFO  - 2019-11-21 08:49:37.896; org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer; Consumer stopped
INFO  - 2019-11-21 08:49:37.897; org.springframework.data.elasticsearch.client.TransportClientFactoryBean; Closing elasticSearch  client
INFO  - 2019-11-21 08:49:39.144; com.alibaba.druid.pool.DruidDataSource; {dataSource-1} closed
